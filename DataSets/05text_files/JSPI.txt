bradley terry model widely often beneficially used rank objects paired comparisons underlying assumption makes ranking possible existence latent linear scale merit equivalently kind transitiveness preference situations sensory comparisons products assumption unrealistic contexts although bradley terry model appears significantly interesting linear ranking sense aim propose dimensional extension bradley terry model accounts interactions compared objects methodological point view proposition seen multidimensional scaling approach context logistic model binomial data maximum likelihood investigated asymptotic properties derived order construct confidence ellipses diagram dimensional scores illustrative example based real sensory data dimensional model inspect lack fit bradley terry model c elsevier b v reserved proportional hazards regression model commonly used evaluate relationship survival covariates covariates frequently measured error substituting mismeasured values true covariates leads biased estimation hu et al biometrics proposed base estimation proportional hazards model covariate measurement error joint likelihood survival covariate variable nonparametric maximum likelihood estimation npmle used simulations conducted assess asymptotic validity approach derive rigorous proof asymptotic normality npml estimators c elsevier b v reserved let theta mode probability density theta n kernel estimator case theta n known fulfill central limit theorem satisfies moderate deviations principle apply result analysis confidence intervals mode case bandwidth small range theta n satisfies central limit theorem obtain moderate deviations upper bound kernel mode estimator application result give upper bound strong convergence rate theta n assumptions strong consistency kernel mode estimator known c elsevier b v reserved analysing k variate data sets randles j amer statist assoc considered hyperplanes going k data points origin introduced empirical angular distance two k variate data vectors based number hyperplanes called interdirections separate two points proposed multivariate sign test based interdirections present analogous concept namely lift interdirections measure regular distances data points empirical distance two k variate data vectors determined number hyperplanes separate two points case considered hyperplanes going k distinct data points invariance convergence properties empirical distances considered lift interdirections together randles interdirections allow building hyperplane based versions optimal testing procedures developed hallin paindaveine ann statist statistical data analysis based l norm related procedures b birkhauser basel pp bernoulli c ann statist appear broad class location time series problems resulting procedures generalize univariate signed rank procedures affine invariant asymptotically invariant group monotone radial transformations acting standardized residuals consequently asymptotically distribution free class elliptical distributions optimal correctly specified radial densities several cases enjoy uniformly good efficiency behavior asymptotic properties confirmed monte carlo simple robustness conducted remarkable test construction value test statistic depends data cloud geometrical notions data vectors oriented hyperplanes relations c elsevier b v reserved consider problem updating beliefs binary random variables probability assessments elicited based information varying quality propose threshold model bayesian updating procedure measures location correlation specified updating possible main aspect model jeffrey conditionalization according rule necessary model assessments relate quantities interest fully parametric way motivated practical issue large company needs manage assets future expenditure c elsevier b v reserved consider classification procedures exponential populations order populations parameters known define behavior classification rule takes account additional information outperforms likelihood ratio based rule two populations considered moreover behavior rule two populations compare misclassification probabilities classical ones type ii censorship usual practice considered obtained performance two populations evaluated simulation c elsevier b v reserved extend basic result huber least favorable distributions setting conditional inference approach based notion log gateaux differentiation perturbed models whereas huber considered intervals fixed width location parameters average coverage rates error models longest confidence intervals conditional location configuration sample version problem global solution one changes configuration configuration asymptotically conditionally least informative shape minimizes conditional fisher information characterize asymptotic solution within huber contamination model c elsevier b v reserved notion linear sufficiency general gauss markov model extended general multivariate linear model specific set estimable functions general formula difference dispersion matrix blue original model transformed model provided brings contributions theory linear sufficiency moreover general formula change blue due transformation obtained analysis leads known besides linear sufficiency admissibility linear statistic extended multivariate case c elsevier b v reserved reliable multinomial probabilistic group testing models incomplete identification assume every pooled items none k attributes one causing contamination group possessing latter attribute discarded others collected separated according attributes found objective choose optimal group size pooled screening collect prespecified numbers items various types minimum testing expenditures derive exact underlying distributions stopping times enabling us optimal procedures numerical methods c elsevier b v reserved number authors proposed clinical trial designs involving comparison several experimental treatments control treatment two stages end first stage promising experimental treatment selected experimental treatments dropped trial provided good enough selected experimental treatment compared control treatment one subsequent stages analysis data trial problematic treatment selection possibility stopping interim analyses aspects lead bias maximum likelihood estimate advantage selected experimental treatment control inaccurate coverage associated confidence interval evaluate bias maximum likelihood estimate propose bias adjusted estimate propose approach construction confidence region vector advantages experimental treatments control based ordering sample space regions accurate coverage although necessarily unbounded confidence intervals advantage selected treatment obtained confidence regions accurate coverage standard confidence interval based upon maximum likelihood estimate asymptotic standard error c elsevier b v reserved large sample properties modified monte carlo integration method locally antithetic variates proposed haber math comput provided mild assumption integrand c function moreover asymptotic distribution modified monte carlo estimator obtained condition furthermore propose consistent variance estimation method avoids replicated procedure considered haber reduces efficiency integration technique basis achieved addition integration framework method may conveniently applied environmental sampling setting c elsevier b v reserved give sufficient conditions establish central limit theorems boundary estimates poisson point processes considered estimates obtained smoothing bias corrected extreme values point process smoothing leads gaussian asymptotic distributions pointwise confidence intervals new unidimensional multidimensional examples provided c elsevier b v reserved information based criterion determining number clusters problem regression clustering proposed probabilistically structured population proposed criterion selects true number regression hyperplanes probability one among class growing sequences classifications number observations n population increases infinity simulation presented c elsevier b v reserved probability select correct model calculated likelihood ratio based criteria compare two nested models extended two models true difference twice maximised log likelihoods approximately noncentral chi square distributed d f difference number parameters noncentrality parameter noncentral chi square distribution approximated twice minimum kullback leibler divergence mkld best fitting simple model true version extended model mkld probability select correct model increases approximately proportionally number observations observations performed conditions new set observations performed different conditions model parameters may depend conditions estimated set observations separately increase observations go together increase number model parameters case power likelihood ratio test increase increasing number observations probability choose correct model aic increase set observations mkld mkld less probability decrease probability choose correct model bic always decrease sometimes initial increase small number observation sets illustrated simulation set five nested nonlinear models binary data c published elsevier b v weibull distribution widely used lifetime data analysis example time occurrence tumors human populations laboratory animals time occurrence tumors generally assumed distributed weibull distribution moreover engineering voltage levels failure occurred electrical cable insulation distributed weibull distribution comparing two independent weibull distributions often assumed scale parameter altered propose simple accurate procedure obtain inference concerning ratio two scale parameters two independent distributions performance proposed method assessed monte carlo simulation numerical proposed method extremely accurate even small samples method applied set real life data c elsevier b v reserved faced sampling frame imperfect correspondence target population survey researcher must decide whether frame expend resources correct imperfections one consideration effects frame imperfections precision estimate simulation techniques explores effects frame imperfections precision estimate population total simple stratified random sampling factors studied amount imperfection frame nature correspondence frame units population elements population coefficient variation correlation weights used correct frame imperfections measure interest recommendations planning survey design presented based upon c elsevier b v reserved estimating proportion people bearing sensitive attribute community mitigate possible evasive answer biases warner j amer statist assoc introduced technique randomized response rr human surveys way protecting individual privacy chaudhuri mukerjee calcutta statist assoc bull randomized response theory techniques marcel dekker new york presented modification allowing direct response dr option attribute appear stigmatizing enough warner many followers restrict application rr devices surveys selection exclusively simple random sampling replacement chaudhuri j statist plann inference pakistan j statist b calcutta statist assoc bull showed efficacy devices sample selection general unequal probabilities possibly even without replacement present theories unbiased estimation proportion along unbiased estimation variances estimators compulsory optional rr gathered persons sampled varying probabilities gains efficiency allowing dr option rather rr compulsion illustrated numerically simulation data c elsevier b v reserved brief account life work istvan vincze prominent hungarian statistician given contributions various topics discussed include empirical distribution kolmogorov smirnov information theory cramer frechet rao inequality estimation density characterization problem c elsevier b v reserved present work class polynomials introduced defined certain recursive scheme associating n th member class previous k members class wide enough accommodate well known families orthogonal polynomials legendre hermite chebyshev laguerre etc well recently studied fibonacci polynomials order k several extensions generating function approach proved new class closed tinder operations convolution partial summation general developed exploited investigation number probability applications pertaining occurrence runs scans sequences binary trials c elsevier b v reserved research little note history combinatories present tentative short biography henri delannoy survey notable works answers question raised title works related lattice paths enumeration called delannoy numbers first general way solve ballot like problems c elsevier b v reserved distributional properties random variable number inversions associated random bimodal permutations considered especially probability generating function moments cumulants given asymptotic properties discussed c elsevier b v reserved wide class q distributions defined stochastic model sequence bernoulli trials conditional probability success nth trial given k successes occur trial varies geometrically n k let x n number successes nth trial y k number trials occurrence k th success q factorial moments random variables x yk derived usual factorial moments x n connected q factorial moments q stirling numbers first kind deduced ascending factorial moments y k particular case success probability depend n obtained probability generating function c elsevier b v reserved consider posets lattice paths endowed natural order begin structures give algebraic condition recognize ones posets lattices next class dyck lattices e lattices dyck paths give recursive construction last section devoted presentation couple open problems c elsevier b v reserved combinatorial designs widely used construction self dual codes recently new methods constructing self dual codes established orthogonal designs generalized orthogonal designs diophantine equations gf p methods led construction many new self dual codes small finite fields rings propose methods generate self dual codes gf p moreover apply shortening padding obtain self orthogonal codes gf p primes p c elsevier b v reserved draws attention members q confluent hypergeometric family discrete distributions either special properties ii arise steady state distributions interesting markov chains include exton o u distributions ii q hyper poisson morse confluent bailey daum confluent q chu vandermonde distributions c elsevier b v reserved new approach used determine transient probability functions classical queueing systems m m m m h m m h catastrophes new solution method uses dual processes randomization lattice path combinatorics method reveals transient probability functions m m h m m h catastrophes mathematical form c elsevier b v reserved suitable transformations orthogonal polynomials lead polynomials nonnegative coefficients work asymptotic normality nonnegative coefficients polynomials derived based nature weight function orthogonal polynomials particular orthogonal polynomial cases classical semi classical systems included well singular behaved pollaczek polynomial case c elsevier b v reserved two sample say x sample y sample non parametric testing problem two joint null distributions statistic similar galton statistic either number y runs maximum length y runs derived two well known combinatorial associated lattice paths c published elsevier b v diffusion walk z random walk unit step vectors arrow arrow particles different sources opposite charges cancel meet lattice cancellation principle applied enumerate diffusion walks shifted half planes quadrants octants three dimensional version considered summing time calculate expected numbers visits first passage probabilities comparing quantities analytically obtained expressions leads interesting identities many involving integrals products chebyshev polynomials first second kind explore expected number visits means diffusion octant bijectively mapped onto combinatorial structures like pairs non intersecting dyck paths vicious walkers bicolored motzkin paths staircase polygons second octant arrow paths confined third hexadecant enumerated left turns c elsevier b v reserved introduce weighted precedence maximal precedence tests testing two distribution functions equal extension precedence life test first proposed nelson technometrics maximal precedence test proposed balakrishnan ng hayakawa et al eds system bayesian reliability essays honor prof richard e barlow th birthday world scientific singapore pp null distributions test derived present exact power functions lehmann alternative compare exact power well simulated power location shift weighted precedence maximal precedence tests original precedence maximal precedence tests next extend test procedures type ii progressive censoring critical values combination sample sizes censoring schemes r presented examine power properties weighted precedence maximal precedence tests location shift alternative monte carlo simulations two examples presented illustrate test procedures discussed concluding remarks c elsevier b v reserved consider multivariate splitting model n n n k n nk k arbitrary necessarily independent random variables taking values n assume rao rubin condition satisfied n n assume file conditional distribution vector n n k given n convolution type characterizations related model k first considered shanbhag j appl probah extension binomial damage model established rao rubin sankhya ser extended k rao srivastava sankhya ser present alternative set conditions distribution n characterized apply result discrete distributions c elsevier b v reserved let u n denote set unrestricted lattice paths run n permitted steps perhaps horizontal step let e n denote set paths u n run strictly horizontal axis except initially first cut paste bijection relates points paths e n points paths u n apply obtain area enumeration paths involving narayana distribution extend cut paste bijection formula relating factorial moments paths e n factorial moments paths u n c published elsevier b v life characterized nonnegative random variable associated life two notions interesting applications biomedical research engineering notions random remaining life certain age equilibrium stationary limit age tends infinity current investigation comparisons three notions stochastically expectation discussed moments inequalities based comparisons presented inequalities used develop testing exponentiality orderings based comparisons c elsevier b v reserved upper sharp bounds mean total time test based type censoring samples terms various scale units presents numerical evaluation obtained bounds c elsevier b v reserved statistical modeling selecting optimal model class candidates critical issue past three decades number model selection criteria proposed based estimating kullback information theory dover mineola ny p directed divergence model generating data fitted candidate model akaike second international symposium information theory akademia kiado budapest hungary pp ieee trans automat control ac information criterion aic first aic justified general framework result offers crude estimator directed divergence one exhibits potentially degree negative bias small sample applications biometrika corrected akaike information criterion biometrika aicc adjusts bias consequently often outperforms aic selection criterion aicc less broadly applicable aic since justification depends upon structure candidate model aic biometrika improved version aic featuring simulated bias correction recently model selection criteria proposed based estimating kullback information theory dover mineola ny p symmetric divergence generating model fitted candidate model statist probab lett austral new zealand j statist kic kicc kici criteria devised target symmetric divergence manner aic aicc aic target directed divergence aicc justified nonlinear regression framework hurvich tsai biometrika justify kicc framework propose versions aici kici suitable nonlinear regression applications evaluate selection performance aic alcc aic kic kicc kici simulation generally indicate improved criteria outperform corrected criteria turn outperform non adjusted criteria moreover kic family performs favorably aic family c elsevier b v reserved present obtains point estimators exponentiated weibull parameters three parameters distribution unknown maximum likelihood estimator generalized maximum likelihood estimator bayes estimators proposed three parameter exponentiated weibull distribution available sample type ii censored independent non informative types priors considered unknown parameters develop generalized maximum likelihood estimator bayes estimators although proposed estimators cannot expressed dice closed forms easily obtained appropriate numerical techniques performances estimators studied basis risks computed separately linex loss squared error loss functions monte carlo simulation technique example considered illustrate estimators c elsevier b v reserved inference multiparameter interest presence nuisance parameters oftentimes based profile likelihood function behave true likelihood function several adjustments profile likelihood function proposed consider additive adjustment aims reducing score information biases score function order o order o n adjustment applicable wide generality since allows interest nuisance parameters vector valued derive bartlett correction adjusted profile likelihood ratio statistic obtain closed form expressions class generalized linear models simulation compares performance usual profile likelihood ratio test adjusted profile likelihood ratio test associated bartlett coffected test c elsevier b v reserved two stage procedures multiple comparisons average location parameters two parameter exponential distributions heterocedasity including one two sided confidence intervals proposed intervals used identify subset includes worse average treatments experimental design identify better average worse average much different average products agriculture stock market medical research auto models upper limit critical values obtained recent techniques given lam proceedings second international advanced seminar workshop inference procedures associated statistical ranking selection sydney australia august comm statist simulation comput b approximate critical values better approximate critical values bonferroni inequality developed example comparing four drugs treatment leukemia given proposed methodology c published elsevier b v regularly varying tails estimation index regular variation tail index gamma often performed classical hill estimator statistic strongly dependent number k top order used asymptotic bias k increases unless underlying model strict pareto model first basis asymptotic structure hill estimator different k values propose asymptotically best linear bl unbiased estimators tail index similar derivation basis log excesses scaled log spacings performed adequate weights largest log observations provided asymptotic behaviour estimators derived compared alternative estimators asymptotically finite samples overall may say even asymptotic equivalent estimators may exhibit diversified finite sample properties c elsevier b v reserved consider one fundamental statistical problems namely inference mean standard deviation coefficients skewness kurtosis unknown univariate distribution assuming distributional form parent population unknown focus attention moment based inference well known method moments estimates population measures consideration sample mean standard deviation coefficients skewness kurtosis despite frequently used statistical summaries comes surprise full joint distribution previously studied derive general theoretical result large sample asymptotic joint distribution four estimators simulation explore validity result means approximating biases variances covariances estimators finite sample sizes theoretical result used obtain asymptotically distribution free inferential procedures population measures original interest specifically propose investigate efficacy bias corrected non bias corrected methods point estimation confidence set construction discuss relevance developed methodology end aid model formulation c elsevier b v reserved propose testing procedure due robinson j amer statist assoc testing deterministic seasonality versus seasonal fractional integration new statistic based score principle developed simultaneously test order integration seasonal component need seasonal dummies tests standard null local limit distributions finite sample critical values tests computed experiments based monte carlo sizes asymptotic tests large larger sizes associated superior rejection frequencies compared finite sample based tests quarterly data real consumption income canada uk japan variables seasonally fractionally integrated three countries without need deterministic seasonal dummies evidence series may seasonally fractionally cointegrated c elsevier b v reserved problem classification multiple q variate observations without time effect individual develop new classification rules populations certain structured unstructured mean vectors certain covariance structures new classification rules effective number observations large enough estimate variance covariance matrix computational schemes maximum likelihood estimates required population parameters given apply two real data sets well simulated data set c elsevier b v reserved consider wide set statistical models extend poisson distribution models obtained weighted versions poisson family approximated log linear model general conditions new models contain overdispersed underdispersed distributions parametrized mean variance classical data set analyzed usefulness new models c elsevier b v reserved joint distribution x n n geometric distribution x sum n d exponential variables independent n present basic properties class mixed bivariate distributions discuss possible applications include marginal conditional distributions joint integral transforms infinite divisibility stability respect geometric summation discuss maximum likelihood estimation connected distribution example finance n represents number consecutive positive daily log returns currency exchange rates illustrates modeling potential laws c elsevier b v reserved many longitudinal recurrent events interest assessing recurrences vary time across treatments strata population usual analyses data assume parametric form distribution recurrences time consider semiparametric model analysis longitudinal data collected panel counts model non homogeneous poisson process multiplicative intensity incorporating covariates proportionality assumption heterogeneity accounted model specific random effects key feature model regression splines model distribution recurrences time flexible robust method relaxing parametric assumptions addition quasi likelihood methods proposed estimation requiring first second moment assumptions obtain consistent estimates simulations method produces estimators rate bias whose standardized distributions well approximated normal usefulness approach especially exploratory illustrated analyzing designed assess effectiveness pheromone treatment disturbing mating habits cherry bark tortrix moth c elsevier b v reserved investigates application mean powerful invariant test problem testing joint ma ma disturbances joint ar ar disturbances linear regression model mean powerful invariant test introduced begum king mean powerful invariant test composite null composite alternative comp statist data analysis forthcoming based generalized neyman pearson lemma optimal test certain composite hypotheses mean powerful invariant test computationally intensive previous applications involved testing problems whose null hypotheses reduction invariance arguments one dimensional first application involving null alternative hypotheses two dimensional monte carlo experiment conducted assess small sample performance test encouraging increase dimension increase significantly computational effort required apply test c elsevier b v reserved identifying times time intervals intensity function poisson process maximal variety practical problems instance traffic control planning issues involving customer arrivals accident occurrences purpose propose confidence sets intuitive easy obtain makes practicable quick exploratory data analysis may used context mode estimation probability densities current confidence sets mode based assumption least locally unique mode contrast approach retains coverage probability even underlying intensity density flat top even allow intensity constant extreme c elsevier b v reserved testing interval estimation considered common mean several normal populations variances unknown possibly unequal new generalized pivotal proposed based best linear unbiased estimator common mean generalized inference exact confidence interval common mean derived generalized confidence interval illustrated two numerical examples merits proposed method numerically compared existing methods respect expected lengths coverage probabilities powers different scenarios c published elsevier b v spatial optimal sampling design covariance parameter estimation spatial process modeled gaussian random field maximum likelihood ml used estimate covariance parameters log determinant inverse fisher information matrix design criterion run simulations investigate relationship inverse fisher information matrix covariance matrix ml estimates simulated annealing algorithm developed search optimal design among possible designs fine grid since design criterion depends unknown parameters define relative efficiency design consider minimax bayesian criteria designs robust range parameter values simulation presented matern class covariance functions c elsevier b v reserved let x x n sequence independent identically distributed random variables continuous distribution function f let x n x n n order generated sample denote number observations registered random interval x n k x n x n k x n k n k k n k limit k k established asymptotic independence neighboring spacings proved class continuous distributions f c elsevier b v reserved establish general recurrence relations satisfied product moments order bivariate order arbitrary bivariate uniform distribution function moreover present formulae easily compute product moments order bivariate order arbitrary bivariate distribution function positive left endpoints negative right endpoints c elsevier b v fights reserved correspondence analysis appears sensitive modalities margins leading outliers notions influence function hadamard differentiability criterion deciding outlier considered influential c elsevier b v reserved formulate closed form bayesian estimators two complementary poisson rate parameters double sampling data misclassification error free data derive closed form bayesian estimators two misclassification parameters modified poisson model assume determine credible sets rate misclassification parameters additionally mcmc methods determine bayesian estimators three rate parameters misclassification parameters perform limited monte carlo simulation examine characteristics estimators efficacy new bayesian estimators highest posterior density regions examples two real data sets c elsevier b v reserved discusses estimation sojourn time distribution latent state observational data assume observations available event occurred type sampling referred retrospective ascertainment focus information content various constructions likelihood function c elsevier b v reserved distribution linear predictor constructed data driven model selection step linear regression model finite sample cumulative distribution function cdf linear predictor derived detailed analysis effects model selection step given moreover simple approximation complicated finite sample cdf proposed approximation facilitates large sample limit behavior linear predictor cdf fixed parameter case local alternatives focus conditional distribution linear predictor conditional event fixed possibly incorrect model selected unconditional distribution linear predictor studied companion leeb distribution linear predictor model selection unconditional finite sample distributions asymptotic approximations technical report department university vienna c elsevier b v reserved scale families densities theta f x theta infinity problem estimating theta scale invariant loss l theta d rho d theta bound constraint form theta quite general f rho generalized bayes estimator delta respect prior theta infinity minimax estimator dominates benchmark minimum risk equivariant mre estimator obtaining dominance kubokawa integral expression risk difference ierd method actually obtain classes dominating estimators include characterized terms delta companion concerning estimation bounded location parameter capitalizing connection location parameter scale parameter estimation problems implications given namely problems estimating power theta r r equal estimating theta upper bound constraint theta b report briefly similar dominance phenomenon interval constraint form b theta b infinity c elsevier b v reserved consider intrinsic autoregression models multiple resolutions firstly describe method construct class approximately coherent markov random fields mrf different scales overcoming problem marginal gaussian mrf general mrf respect nontrivial neighbourhood structure based approximation non markov gaussian fields gaussian mrfs optimal according different theoretic notions kullback leibler divergence extend method intrinsic autoregressions providing novel multi resolution framework c elsevier b v reserved deal nonparametric kernel estimation regression volatility functions pertaining nonlinear autoregressive model arch errors stationarity ergodicity establish strong uniform consistency asymptotic normality estimators hold without mixing condition require existence marginal densities furthermore rates convergence obtained c elsevier b v reserved properties generalized statistic sample comes skew elliptical distributions several forms probability density functions obtained robustness one sided test family skew normal distributions investigated c elsevier b v reserved likelihood ratio test two component normal location mixture natural parametrisation degenerates non uniqueness null one consequence ambiguity limiting distribution likelihood ratio statistic quite irregular extreme value type rather chi squared another irregular feature likelihood ratio statistic diverges infinity limit theory nonstandard respect well form applying directly likelihood ratio statistic rather approximating stochastic process recently established liu shao address properties null hint power likelihood ratio test may less conventional settings indeed case system local alternative hypotheses quantify extent power reduced large class circumstances reduction power appreciated terms inflation log log factor displacement closest local alternative distinguished null respects properties power local alternatives significantly complex exhibit two types singularity particular two quite different respects small changes local alternative neighbourhood threshold dramatically alter power c elsevier b v fights reserved likelihood widely used statistical applications full parameter obvious direct calculation component interest parameters recent asymptotic theory often want detailed information concerning inference procedure information say distribution function measure departure would permit power calculations detailed display p values range parameter values investigate distribution function approximations obtained minimal information concerning likelihood function minimum often available many applications resulting expressions clearly indicate source various ingredients likelihood basis understanding nonnormality likelihood function affects related p values moreover basis removing computational singularity arises near maximum likelihood value recently developed significance function formulas used c elsevier b v reserved random effects model examined multivariate setting one characteristics measured time point nil reml estimators obtained restriction estimates variance matrices least p d reml greater probability giving full rank estimates variance components matrices regards efficiency estimation location parameter correct specification number random effects needed general reml larger estimates variance model parameters ml c elsevier b v reserved consider parametric regression problems covariates missing random regression parameter remains identifiable natural conditions always observed covariates discrete propose semiparametric maximum likelihood method require parametric specification missing data mechanism covariate distribution global maximum likelihood estimator mle maximizes likelihood whole parameter set exist simple conditions ease computation consider restricted mle maximizes likelihood covariate distributions supported observed values regularity conditions two mles asymptotically equivalent strongly consistent class topologies parameter set c elsevier b v reserved main purpose obtain representation probability measure families measurable space given sub sigma field partially sufficient sense fraser mild hypotheses without densities examples given clarify obtained special situations existence partially sufficient fields c elsevier b v reserved ud experiment estimating given quantile binary response curve sequential procedure whereby step given treatment level used according outcome observations decision made deterministic randomized whether maintain treatment increase one level else decrease one level design points ud rules generate markov chain mode invariant distribution approximation quantile interest main area application ud algorithms phase clinical trials greatest importance able attain reliable small size experiments address issues speed convergence precision quantile estimates procedures theory simulation version ud designs introduced durham flournoy large number cases regarded optimal among ud rules furthermore order improve convergence properties algorithm propose second order ud experiment instead making recent observation bases next step outcomes last two procedure shares number desirable properties corresponding first order designs allows greater flexibility suitable choice parameters new scheme least good first order one leads improvement quantile estimates starting point algorithm relative target quantile c elsevier b v reserved sample surveys sometimes one encounters situation many sampling units one variables interest valued zero negligibly units substantial heavy localization valued units certain segments estimation may inaccurate chosen sample fails capture enough valued units situations adaptive sampling extension initial sample capture additional valued units may serviceable size adaptive sample may often far exceed initial sample present method put desirable constraints adaptive sample size keep latter check examine efficacy method illustrate application estimate total numbers rural earners specific vocations given district india simultaneously several vocations c elsevier b v reserved long computational time required constructing optimal designs computer experiments limited uses practice new algorithm constructing optimal experimental designs developed two major developments involved work one developing efficient global optimal search algorithm named enhanced stochastic evolutionary ese algorithm developing efficient methods evaluating optimality criteria proposed algorithm compared existing techniques found much efficient terms computation time number exchanges needed generating new designs achieved optimality criteria algorithm flexible construct various classes optimal designs retain certain desired structural properties c elsevier b v reserved establish form optimal design choice experiments attributes need number levels testing main effects k attributes choice sets size m give construction optimal near optimal designs small numbers choice sets derive general form determinant information matrix estimating main effects two factor interactions derive optimal designs situation special cases c elsevier b v reserved novel result asymptotic distribution class rank used situation number replications limited whereas number treatments goes infinity large k small n case applied e g data agricultural screening trials usually numbers factor levels large replications per factor level c elsevier b v reserved assume x x iid rv continuous cumulative distribution function finite pth absolute moment aim present sharp upper bounds expectations increments record values measured various scale units derive bounds case parent distribution monotone density monotone failure rate distribution functions attaining bounds characterized c elsevier b v reserved formulates nonparametric maximum likelihood estimation probability measures generalizes consistency result maximum likelihood estimator mle drop independent assumption underlying stochastic process replace assumption stochastic process stationary ergodic present proof employs birkhoff ergodic theorem martingale convergence theorem main result applied parametric nonparametric maximum likelihood estimation density functions c elsevier b v reserved consistency central limit theorem kernel density estimator random sample realization nonstationary alpha mixing process revealed rate convergence depends upon degree dependency structure underlying densities c elsevier b v reserved class tests baseline hazard function cox proportional hazards model general recurrent event model belongs parametric family c bond lambda xi xi element xi proposed finite properties tests examined via simulations asymptotic properties tests contiguous sequence local alternatives studied theoretically application tests general recurrent event model extended minimal repair model admitting covariates demonstrated addition two real data sets used illustrate applicability proposed tests c elsevier b v reserved linear model arbitrary variance covariance matrix zyskind ann math statist provided necessary sufficient conditions given linear function fixed effect parameters best linear unbiased estimator blue conditions hold uniformly possible variance covariance parameters e ublue data assumed normally distributed conditions necessary sufficient parametric function uniformly minimum variance unbiased estimator umvue mixed effects anova models conditions translated terms incidence array facilitates verification ublue umvue properties facilitates construction designs properties c elsevier b v reserved structured total least squares estimator defined via constrained optimization problem generalization total least squares estimator data matrix applied correction satisfy given structural constraints affine structure additional assumptions considered particular toeplitz hankel structured noise free unstructured blocks allowed simultaneously augmented data matrix equivalent optimization problem derived decision variables estimated parameters cost function equivalent problem used consistency structured total least squares estimator general affine structured multivariate model illustrated examples special models modification block hankel toeplitz structures given product analysis cost function iterative algorithm computation structured total least squares estimator proposed c elsevier b v reserved presents discussion properties asymptotic confidence intervals based normalizing transformation cornish fisher inversion studentized statistic normalizing transformation discussed herein removes bias skewness kurtosis cornish fisher inversion obtained edgeworth expansion studentized statistic residual term o n asymptotic mean squared errors simulation discussed c elsevier b v reserved inverse gaussian ig distribution ideal candidate modeling positive right skewed data always reservations ig distribution data analysis partially due fact exact confidence interval involving two ig means available shape parameters equal present approach based modified directed likelihood ratio statistic obtain approximate confidence interval ratio two inverse gaussian means assessed simulation coverage probability proposed approach found accurate even small sample sizes c elsevier b v reserved riesz distributions symmetric cone used introduce class beta riesz distributions fundamental properties distributions established particular effect projection beta riesz distribution give properties independence calculate expectation beta riesz random variable corollary give regression mean riesz random variable determine conditional expectation e u broken vertical bar u v u v two independent riesz random variables c elsevier b v reserved confidence limits response probabilities based sensitivity testing data set saddlepoint approximation conditional distribution developed based give modified algorithm approximate confidence limits parameter interest simulation saddlepoint approximation proper corrections gives better coverage probability direct saddlepoint approximation asymptotic normality approximation apply proposed approximation real data set c elsevier b v reserved investigates asymptotic distribution akaike information criterion aic presents characteristics normal linear regression models bias correction aic studied may noted bias mean e first moment moments investigating behavior aic variance increases number explanatory variables increases skewness kurtosis imply favorable accuracy normal approximation asymptotic expansion distribution function standardized aic derived c elsevier b v reserved present bayesian inference methodology box cox transformed linear mixed model arma p q errors approximate bayesian markov chain monte carlo methods two priors proposed put comparisons parameter estimation prediction future values advantages bayesian approach maximum likelihood method demonstrated real simulated data c elsevier b v reserved considers noninformative priors three stage nested designs turns noninformative prior given li stern one time reference prior satisfying second order matching criterion either variance ratio linear combinations means interest moreover joint probability matching prior variance ratio linear combinations means interest priors compared jeffreys prior light accurately coverage probabilities bayesian credible intervals match corresponding frequentist coverage probabilities c elsevier b v reserved algorithms finding optimal designs three parameter binary dose response models incorporate control mortality described locally bayesian optimal designs models range link functions considered design criteria looked include d optimal d optimal v optimal designs together d optimal designs control mortality parameter regarded nuisance parameter range prior distributions bayesian optimal designs includes uniform trivariate normal combination bivariate normal prior parameters underlying dose response independent uniform prior control mortality parameter c elsevier b v reserved bayesian formulation group testing problem testing error considered assumption testing error follows bernoulli distribution optimal sequences experiments characterized intuitive appealing experiment selection rule eventually select optimal sequences experiments almost surely c elsevier b v reserved balanced incomplete block design nested rows columns denoted bibrc v k k lambda block design plots blocks arranged arrays size k x k thatlambda k lambda r j k lambda c j lambda e j constant depending choice points j lambda r j lambda c j lambda e j number times pair ij occurs row column elsewhere respectively give construction bibrcs utilizing method differences moreover case satisfies conditions exists bibrc q k k lambda q sufficiently large prime power lambda q mod k k k k holds c elsevier b v reserved present two methods construction class universally optimal b x b row column designs b k empty nodes row b k empty nodes column number treatments consideration form odd prime power number designs constructed structurally balanced sense every pair columns used equal number rows proposed designs used universally optimal two factor orthogonal main effect plans arranged incomplete blocks equivalent orthogonal pairs balanced incomplete block designs balanced incomplete block designs two sets treatments two stage experiments incomplete blocks different numbers treatments two stages c elsevier b v reserved finite projective geometries used obtain series taguchi linear graphs involving m runs prime prime power concept maximal linear graph introduced reduce number nonisomorphic linear graphs run maximal linear graphs given examples table nonisomorphic run maximal linear graphs believed complete provided c elsevier b v reserved super simple designs useful construction superimposed codes necessary condition existence super simple balanced incomplete block design v points k v condition sufficient c published elsevier b v generalized kronecker sum used wang wu j amer statist assoc dey midha statist probab lett proc ap akad sci confstruct mixed orthogonal arrays modify methods obtain several families mixed orthogonal arrays new arrays run size less found c elsevier b v reserved problems nonparametric statistical inference reliability survival availability failure rate functions continuous time markov processes discussed assume state space finite shall discuss maximum likelihood estimator generators continuous time markov processes asymptotic properties estimator discussed present extension obtaining asymptotic properties estimators transition matrix reliability survival availability failure rate functions continuous time markov process confidence intervals proposed estimators given give numerical example illustrate c elsevier b v reserved present bayesian decision theoretic model producing via pair wise comparisons set possible rankings given number normal means simulation performed compare constant loss model popular frequentist methods used rank normal means including tukeys method benjamini hochberg procedure model compared bayesian model linear loss function properties compared include probability containing true ranking expected number possible rankings produced c elsevier b v reserved procedure testing simultaneously parametric forms conditional mean conditional variance functions real valued heteroscedastic time series model proposed wald test statistic based vector whose components suitable normalized sums weighted residual series test consistent fixed alternatives local power two sequences local alternatives studied lan property parametric model interest established experiment conducted test performs well examples tested c elsevier b v reserved dependence structure observed process induced temporal aggregation time evolving hidden spatial phenomenon addressed data described means chain graph models algorithm compute chain graph resulting temporal aggregation directed acyclic graph provided chain graph best graph covers independencies resulting process within chain graph class sufficient condition produces memory loss observed process respect hidden origin analyzed examples used illustrating algorithms c elsevier b v reserved address problem detecting deviations binary sequence randomness random number rng pseudorandom number generators prng namely consider lull h given bit sequence generated bernoulli source equal probabilities alternative h sequence generated stationary ergodic source differs source h data compression methods used basis testing describe two new tests randomness based ideas universal coding known statistical tests suggested ones applied testing prngs experiments power new tests greater many known algorithms c elsevier b v reserved consider two test testing strict ttt transform order two life distributions interest give asymptotic distributions compare tests related tests terms pitman asymptotic efficiency present performance asymptotic normality tests c elsevier b v reserved problem change point detection case composite hypotheses considered assume distribution functions observations unknown change point belong parametric family true value parameter family unknown belongs two disjoint sets observations change point respectively new criterion quality change point detection introduced modifications generalized cusum grsh girshick rubin shiryaev methods considered characteristics analyzed comparing characteristics priori boundary quality change point detection establish asymptotic optimality methods family distributions change point consists one element c elsevier b v reserved several candidate tests available given testing problem nice properties respect different criteria efficiency robustness desirable combine discuss various combined tests based asymptotically normal tests means two standardized tests contiguous alternatives close maximum two tests appears overall best performance compared forms combined tests considered retains power compared better one two tests combined application testing zero location shift two groups studied normal wilcoxon median tests combined tests structural differences joint convergence asymptotic correlation tests easily derived usual asymptotic arguments tests developed novel application martingale theory obtain asymptotic correlations estimators simulation performed examine small sample properties combined tests illustrate methods real data example c elsevier b v reserved detail asymptotic behavior record values types archimedean copula processes refining form corresponding normalizing constants c elsevier b v reserved discuss previsions induced multi valued mappings fit framework behavioural theory imprecise probabilities notions coherence natural extension theory used generalise existing elegant straightforward manner clear example explanatory unifying power c elsevier b v reserved randomization industrial scientific experiments equipment meant randomizing order application levels treatments units definition inadequate render independent error terms randomization requires independent resettings treatment levels levels preceding run incorrectly explains randomization carried need reset levels treatment one run next never emphasized simple example statistical tests biased treatments even levels one treatment independently reset even expected mean squares recognize restrictions randomization usual f test give predictable numerator denominator correlated experimental design equipment includes experiments chemical automobile pharmaceutical aeronautical industries statistical interpretation data experiments misleading books experimental design must emphasize independent resetting levels carefully emphasize random assignment treatment levels c elsevier b v reserved implement privacy problem moors j amer statist assoc model mangat et al commun statist theory methods singh et al j statist plann inference presented several strategies alternative moors model models may lose large portion data information require cost obtain confidentiality respondents proposed model advantage simplicity previous models protecting confidentiality extend proposed model stratified sampling c elsevier b v reserved mean residual life function interest many fields reliability survival analysis actuarial etc given sample unknown distribution function local linear fitting technique estimate corresponding mean residual life function limit behaviour obtained estimator presented c elsevier b v reserved new method probability value evaluation monotone boolean function example system reliability proposed method based presentation function canonical disjunctive normal form monte carlo procedure assumes random choice form terms arithmetical mean gives approximation probability value estimator unbiased variance estimator calculated proposed method less variance comparison crude monte carlo method c elsevier b v reserved propose analyse development disease sanogenesis curves model result interacting exitatory inhibitory factors disease assuming dimensional data describing disease course driven latent complex valued gaussian process markovian structure identify sanogenesis curve real part covariance function latent process applying techniques stochastic process theory partially inverse functions theory finding allows estimate model parameters addition sanogensis curve suggests new model survival times failures deads observed critical time periods crises defined sanogenesis curve illustrate approach analyzing two real data sets medicine c published elsevier b v method constructing efficient two level fractional factorial designs analysis two step production processes described first design analyzing first step production process chosen chosen design extended one analyzing steps design extended way number different combinations first step small c elsevier b v reserved ghosh fairchild j statist plann inference sen rao eds handbook bioenvironmental public health north holland amsterdam p proposed model drawing inference treatment interactions two period crossover trial presented method subgrouping group present another method subgrouping purpose drawing inference treatment interactions new method based threshold level critical adjacent factor caf majority rule compare two methods subgrouping three performance measures used comparison first measure probability identifying correct number subgroups second measure probability correctly placed subgroup condition number subgroups correctly identified third measure defined ordered lowest highest differences responses two treatments placed subgroup method third measure determines number distinct subgroups beyond single subgroup really belong extensive simulations used calculating estimated numerical values performance measures comparing methods subgrouping c elsevier b v reserved given sequence n d copies bivariate random vector x y continuously distributed y denote m n l l n maximal sum first coordinates intervals length second coordinates form increasing runs strong law large numbers maximal gain longest increasing runs e m n l n l n length longest increasing run n infinity proved frolov et al statist probab lett x finite moment order r assuming x finite mean derive necessary sufficient conditions strong law turn simple unusual describe thoroughly asymptotics l n c published elsevier b v concerns locally optimal experimental designs nonlinear regression models based functional approach introduced ser statist approach locally optimal design points weights studied implicitly given functions nonlinear parameters included model representing functions taylor series enables analytical solution optimal design problem many nonlinear models wide class models introduced includes particular three parameters logistic distribution hyperexponential rational models models construct analytical solution studying efficiency locally optimal designs criterion optimality well known d criterion considered c elsevier b v reserved discuss problem testing homogeneity entropy diversity measures extension asymptotic concerning distribution reasonable homogeneity statistic proposed improvements based upon corrections similar satterwhaitte authors alternative approach consider bootstrap procedure problem making multiple comparisons diversity measures considered either asymptotic bootstrap approach methods illustrated data concerning problem extinction dinosaurs present simulation determine relative merits methods main corrections asymptotic theory bootstrap procedure good balance precision moderate computational cost c elsevier b v reserved many applications one interested detect certain known patterns mean process smallest delay asymptotic framework allows capture feature class appropriate sequential nonparametric kernel procedures local nonparametric alternatives new theorem convergence normed delay associated sequential detection procedure holds dependent time series weak mixing condition result suggests simple procedure select kernel finite set candidate kernels may interest practical point view two new theorems existence explicit representation optimal kernels minimizing asymptotic normed delay illustrated examples c elsevier b v reserved describe cost constraint based decision theoretic approach design screening trials goal identify promising candidates future decide whether accept reject product algorithmic method optimizing approach presented method utilizes highly flexible structure reflect variety decision experimental costs constraints designs produced range single stage fully sequential depending sampling cost functions constraints designs generalize extend previously available often achieving meaningful improvements approach used variety problems operating characteristics designs described c elsevier b v reserved efficiencies split plot design relative split block design experiments testing problems explored definition efficiency based sample size experiments efficiencies experiments testing problems depend hypotheses precision tests practical example given showing determine relative efficiency split block design split plot design testing problems c elsevier b v reserved new theoretical simulation program approximate determination minimal size experiments compare levels fixed factor balanced mixed classifications analysis variance cases exact f test exists presented exact f test exists approximate test denominator degrees freedom d f usually known d f upper bound derived calculate bounds sample size approximate test used calculate expectation size experiment simulation experiments used guarantee given precision requirement c elsevier b v reserved consider process jumps among finite set states random times spent semi markov processes transitions follow markov chain sojourn distributions depend connecting states suppose process started far past achieving pip stationary consider non parametric estimation modelling log hazard sojourn times linear splines obtain maximum penalized likelihood estimators data consist several d windows consistency grenander method sieves c elsevier b v reserved characterizations family distributions context reliability theory placing emphasis particular family member yule distribution particular distribution non negative integer valued random variable x e x infinity uniquely identified belong class distributions consisting geometric waring negative hypergeometric distributions anyone following conditions satisfied mean residual life linear function time b vitality function linear function time c product hazard rate mean residual life constant characterizations yule distribution based reliability measures size biased version provided continuous analogues considered include characterizations exponential beta first second kind distributions c elsevier b v reserved posterior mode standardized prior density proposed estimate mean vector parameter potential usefulness discussed priors include conjugate prior generalized forms prior density factored standardized prior density supporting measure density discard latter density calculate posterior mode mean standardized prior density treatment makes choice prior density flexible implications treatment discussed c elsevier b v reserved problems arise likelihood ratio test identification mixture distribution well known non identifiability parameters null corresponding boundary point parameter space approach problem testing homogeneity mixture two components ghosh sen took account specific problems general assumptions obtained asymptotic distribution likelihood ratio test statistic result requires separation condition completely satisfactory possible remove condition assumptions involve second derivatives density c elsevier b v reserved introduces adaptive weighted maximum likelihood estimators binary regression models asymptotic distribution model established asymptotic confidence intervals derived finite sample properties studied simulation clean datasets proposed adaptive estimators efficient non adaptive ones even moderate sample sizes outlier contaminated datasets comparable robustness asymptotic confidence intervals actual coverage levels model close nominal levels even moderate sample sizes reasonably stable contamination c elsevier b v reserved considers generalized maximum likelihood asymptotic power one tests aim detect change point logistic regression alternative specifies change occurred parameters model guaranteed non asymptotic upper bound significance level tests presented cases test supports change point propose maximum likelihood estimator point present regarding asymptotic properties estimator field application approach occupational medicine lot chemical compounds agents called threshold limit values tlvs specified applications test maximum likelihood estimation change point actual problem encountered real data c elsevier b v reserved generalized cross validation gcv method popular technique selection tuning parameters smoothing penalty standard tool select tuning parameters shrinkage models recent works computational ease robustness compared cross validation method makes competitive model selection well well known gcv method performs well linear estimators linear functions response variable ridge estimator may perform well nonlinear estimators since gcv emphasizes linear characteristics taking trace projection matrix aims explore gcv nonlinear estimators extend correlated data longitudinal expect nonlinear gcv quasi gcv developed similar tools selection tuning parameters linear penalty models penalized gee models c elsevier b v reserved estimation linear functions two order restricted normal means considered variances unknown possibly unequal replace unknown variances sample variances construct isotonic regression estimators call plug estimators estimate ordered normal means squared error loss necessary sufficient condition given plug estimators improve upon unrestricted maximum likelihood estimators uniformly estimation linear functions ordered non nal means variances known restricted maximum likelihood estimator always improves upon unrestricted maximum likelihood estimator uniformly variances unknown plug estimator always improve upon unrestricted maximum likelihood estimator uniformly c elsevier b v reserved o limit risks disclosures releasing data public suggested statistical agencies release multiply imputed synthetic microdata example released microdata fully synthetic comprising random samples units sampling frame simulated values variables released microdata partially synthetic comprising units originally surveyed collected values e g sensitive values risk disclosure values key identifiers replaced multiple imputations presents inferential methods synthetic data multi component estimands particular procedures wald likelihood ratio tests performance procedures illustrated simulation c elsevier b v reserved extend traditional inverse sampling multiple case modify multiple inverse sampling design version taking simple random sample beginning similar chang et al j statist plan inference truncated version similar chang et al j statist plan inference murthy sankhya develop unbiased estimators unbiased variance estimators unbiased estimators applied frequently used sampling scheme called quota sampling practitioners multiple inverse sampling may viewed improved version quota sampling sense estimators estimating proportions weights subpopulations efficient robust available estimators small simulation c elsevier b v reserved m robust designs defined constructed misspecified linear regression models possibly autocorrelated errors discrete design space designs minimize mean squared errors linear regression models correct uncorrelated errors two robust constraints control change bias change variance model departures simulated annealing algorithm applied construct m robust designs examples given m robust designs compare minimax robust designs c published elsevier b v two classes designs resolution v constructed one factor time techniques facilitate sequential learning economical run size regular v k p designs comparisons d efficiency designs given assess suitability proposed designs d efficiencies dramatically improved addition runs c elsevier b v reserved explores possibility nonparametric dependence characteristics evaluate biometric systems algorithms extensions classical rank correlation coefficients case given number top matches used investigated difficulties coefficients capturing total correlation noted version scan statistic measures co occurrence rankings two arbitrary algorithms studied exact covariance structure statistic found pair independent algorithms general case asymptotic normality derived classical linear rank concept copula useful nonparametric dependence characteristics applied example feret face recognition technology program demonstrated random scores considered recognition methods modeled two parameter family copulas exhibiting strong tail dependence c elsevier b v reserved data collected rectangular lattice common many areas models used often simplifying assumptions assumptions include axial symmetry spatial process separability different methods testing axial symmetry separability considered sample periodogram simple satisfactory tests hypotheses tests separability given axial symmetry power small lattices c elsevier b v reserved let rho rho p population canonical correlation coefficients normal distribution considers estimation delta delta p delta rho rho p decision theoretic way since distribution delta complicated two staged estimation usual method far e first good estimator matrix whose eigenvalues delta eigenvalues estimators delta directly estimate delta evaluate estimators respect quadratic loss function propose new class estimators dominance usual estimator c elsevier b v reserved one sided confidence intervals binomial negative binomial poisson distributions considered standard wald interval suffers serious systematic bias coverage one sided score interval alternative confidence intervals better performance considered coverage length properties confidence intervals compared numerical analytical calculations implications testing discussed c elsevier b v reserved availability systems undergoing periodic inspections studied perfect repair replacement failed system carried requiring either constant random length time model system assumed good new completion inspection repair model b maintenance corrective actions taken time inspection system still working condition system assumed inspection unlike studied related sarkar sarkar j statist plann inference model assumes periodic inspections take place fixed time points repair replacement case failure general instantaneous availability steady state availability two models presented assumption random repair replacement time c published elsevier b v convergence rates empirical bayes estimation exponential family studied first develop approach obtaining bound empirical bayes estimators application approach o n bound rate priors bounded compact support second construct empirical bayes estimator kernel sequence method rate convergence o n ln n upper bound rate much faster compared earlier published assumption c elsevier b v reserved addresses problem testing whether vectors regression coefficients equal two independent normal regression models error variances unknown problem poses severe difficulties frequentist bayesian approaches statistical inference former approach normal testing theory apply unrelated variances latter prior distributions typically used parameters improper hence bayes factor based solution cannot used propose bayesian solution problem subjective input considered first generate objective proper prior distributions intrinsic priors bayes factor model posterior probabilities well defined posterior probability model used model selection tool consistent procedure testing hypotheses compared frequentist approximate tests proposed c published elsevier b v objective suggest estimators population mean mu x presence scrambled responses coefficient variation cv c x x known absence error ii guessed value c x coefficient variation c x x available merits suggested estimators examined numerical illustrations c elsevier b v reserved two level fractional factorial designs efficient terms aberration aliasing properties classified four types designs resolution iv half fraction designs even designs five column designs join designs designs concise grid representations simple interpretations aliasing structure new efficient run designs presented blocking designs considered c elsevier b v reserved adaptive design clinical trial prognostic factors two treatments described generalised urn model random environment evolution urn composition expressed recurrence equation fits robbins monro scheme stochastic approximation ordinary differential equation method used obtain strong laws besides central limit theorems obtained useful inference parameters clinical trial c elsevier b v reserved compare asymptotic relative efficiency several regression calibration methods correcting measurement error internal validation data single covariate measured error estimators consider appropriate main hybrid validation designs latter includes internal validation may include external validation data although methods consider produce consistent estimates method proposed spiegelman et al medicine asymptotically smaller variance methods methods measurement error correction illustrated effect utero lead exposure infant birth weight c elsevier b v reserved application screening test ascertaining status characteristic individuals certain population accuracy screening test often depends dichotomization test outcome variable need favorable dichotomizer optimal performance test obtained determination optimal dichotomizers considered decision theoretic bayesian approach parametric models introduced continuous numerical discrete ordinal categorical screening variables optimal dichotomization adjusted individual dependent covariates discussed within model parameters unknown predictive inference optimal dichotomizers emphasized c elsevier b v reserved herman chernoff made fundamental contributions analytical computational methods solving optimal stopping problems brownian motion showed optimal stopping c problems closely related basic problems sequential analysis singular stochastic control gives survey related developments describes recent applications option valuation financial economics c published elsevier b v three approaches sequential analysis reviewed chernoff development wald approach dynamic programming analysis developed author ago path averaging approach exploits random walk properties log posterior given last two approaches led explicit determinations optimal decision boundary associated costs limit small sampling cost general number hypotheses particular interest path averaging approach applies state estimation hidden markov model leads eq gives immediate indication effectiveness different states estimated c elsevier b v reserved nonlinear regression model considered design variable may function previous responses aim construct confidence intervals parameter asymptotically valid order accomplished tilting argument construct first approximation pivotal quantity version stein identity weak expansions determine correction terms accuracy approximations assessed simulation two well known nonlinear regression models first order growth decay model michaelis menten model one two parameters known detailed proofs expansions given c elsevier b v reserved importance elfving geometrical result illustrated showing original proof l used number elfving type without equivalence theorems indicated elementary equivalence theorems follow easily elfving elfving theorem equivalent special case general theorem approximation theory c elsevier b v reserved recent given distribution stopping limes defined compound poisson processes linear boundaries generalization zacks commun statist stochastic models given discrete compound poisson processes main approach reviewed papers sample path analysis leads renewal type equations explicit solutions given c elsevier b v reserved various sequential hypotheses testing reviewed optimal stopping rules related local measure statistical information cases local information approximated l numbers discovered lorden simple rules based approximations asymptotically optimal better order cost single observation c elsevier b v reserved let x nonnegative independent random variables finite expectations x n max x x n value exn obtained prophet mortal hand may k greater equal stopping rules k yielding return e max k x ti n greater equal k optimal return v k n x xn sup e max k x ti supremum stopping rules stop time well known prophet inequality states xi one choice exn v n x xn constant cannot improved n greater equal contrast k best constant d satisfying exn dv n x x x x n x depends way obtain constants c k exk c k v k k x x x xk c elsevier b v reserved consider two stage procedure allocating two treatments yield total n dicholomous responses one treatments known probability success first stage observations may made either treatments observed successes discounted factor beta one treatments must chosen second stage observed successes longer discounted adopt bayesian approach develop continuous time approximation problem turns identical one developed petkau q amer statist assoc examination stopping boundaries bayes risks suboptimal strategies provided solution continuous time problem excellent approximations optimal strategies discrete time problem continuity correction developed cheroff petkau ann probab plays role enhancing naive approximation provided solution continuous time problem c elsevier b v reserved substantial spatio temporal modeling date exists essentially addresses issue process change certain time fact look change points purely time series data customary form propose model involving mean level shift see little attempting capture change association structure pan concern specify flexible ways bridge association across time point still ensure proper joint distribution defined data introducing spatial component evidently adds complication want allow chan e point reflecting change temporal spatial association propose constructive flexible model formulation additive specifications computational concerns benefit availability temporal order illustrate several simulated datasets examine capability model detect different types structural changes c elsevier b v fights reserved aligned rank considered testing hypothese regarding location repeated measurement designs design matrix set measurements orthonormal design may instance used testing linearity turns centered design matrix full rank quite satisfy usual conditions number degrees freedom limiting chi square distribution test statistic null affected unless rather special h hypotheses tested independent derivation limiting distribution given chernoff savage approach passing observed independence choice aligner location problem well known due cancellation may scale problems occur result type score function suitable scale tests possible extension multivariate data briefly indicated c elsevier b v reserved many problems practical interest formulated nonparametric estimation certain function regression function logistic generalized regression function density function conditional density function hazard function conditional hazard function extended linear modeling convenient theoretical framework polynomial splines selected tensor products function estimation problems especially obtaining rates convergence resulting estimates unified manner long time theoretical restricted fixed knot splines log likelihood functions twice continuously differentiable recently stone huang extended theory handle free knot splines present theory extended handle contexts log likelihood function may differentiable specifically establish rates convergence estimation based free knot splines context nonparametric regression corresponding m estimates includes least absolute deviations lad regression quantile regression robust regression special cases d c elsevier b v reserved progressive type h censoring introduced cohen technometrics topic much research question stands whether sensible sampling plan design instead regular type ii right censoring introduce asymptotic progressive censoring model optimal censoring schemes location scale families optimality criterion determinant x covariance matrix asymptotic best linear unbiased estimators present explicit expression criterion conditions boundedness means numerical optimization determine optimal censoring schemes extreme value weibull normal distributions man situations progressive schemes significantly improve upon regular type ii right censoring c elsevier b v reserved order restricted statistical model expressed general form p theta theta epsilon c c convex cone r p general unbiased estimator exists theta particular maximum likelihood estimator ormle biased although aggregate mean square error usually less unrestricted mle urmle nonetheless bias mean square error se single component single linear contrast ormle exceed corresponding component contrast urmle amounts approach infinity dimension increases phenomenon examined detail three examples orthant cone tree order cone simple order cone geometric features cone determine growth rate bias mse studied bias reducing adjustments certain components contrasts ormle suggested orthant tree order models c elsevier b v reserved discuss quite remarkable global markovian structure nucleotides eukaryotic dna strands special emphasis similarity property intra species chromosomes ii reversibility property two complementary strands chromosome c elsevier b v reserved techniques clustering sequences nucleic amino acids application defining viral subtypes hiv basis similarities v loop region amino acids envelope env gene techniques introduced could apply virtually change hiv genes well problems data necessarily viral origin algorithms apply quantitative data found much application engineering contexts compressing images speech called vector quantization involve mapping large number possible inputs much smaller number outputs many implementations particular go name generalized lloyd k means exist choosing sets possible outputs mappings attempt maximize similarities among inputs map single output alternatively minimize measure distortion input output two standard types vector quantization brought bear upon cited problem clustering v loop amino acid sequences clustering compared well known upgma algorithms unweighted pair group method arithmetic averages employed c elsevier b v fights reserved conditional mixture likelihood method absolute difference trait values sib pair estimate genetic parameters underlies commonly used method linkage analysis statistical properties model examined marginal model pseudo likelihood function based sample absolute difference sib traits studied approaches compared numerically genotyping much expensive screening quantitative trait known extremely discordant sib pairs powerful link age tests randomly sampled sib pairs fisher information genetic parameters contained extremely discordant sib pairs calculated marginal mixture model supplement current research showing extremely discordant sib pairs powerful linkage detection demonstrating contain information genetic parameters c elsevier b v reserved appropriate version score statistic test link age sample phase known meioses accurate approximations genome wide significance level obtained large deviation approximation evaluate rice formula expected number upcrossings smooth random process c elsevier b v reserved considers problem homogeneity among groups comparison genomic sequences alternative procedures attach less emphasis likelihood approach alternative measures deal similar homogeneity problems considered approach one sided test considered classical anova decomposition directly adapted sample measures based hamming distance without necessarily going second moments u theory useful decomposition test statistic asymptotic distribution application test real data p value test statistic found via bootstrap resampling c elsevier b v fights reserved test equal means two normal populations without assumption variances usually referred behrens fisher problem exact similar tests known exist excellent approximately similar solutions readily available available tests corresponding critical regions due welch aspin trickett come closest achieving similarity examines numerically welch aspin asymptotic series related trickett welch integral equation formulations problem examples illustrate well behaved tests deviate similarity almost incredibly small amount despite much extensive computation feasible half century ago see irregularities could empirical reflection known nonexistance exact solutions c published elsevier b v course solving variational problem chernoff ann probab obtained appears specialized inequality variance namely standard normal variable x var g x greater equal e g x simplicity usefulness inequality generated plethora extensions well alternative proofs previous papers focused single function inequality covariance matrix k functions leads matrix inequality sense loewner c elsevier b v reserved considers confidence intervals difference two binomial proportions currently used approaches discussed new approach proposed several generally used criteria approaches thoroughly compared widely used wald confidence interval ci far satisfactory newcombe cl new recentered ci score ci good performance recommendations approach applicable different situations given c elsevier b v reserved contemporary exposition moderately quantitative level distribution theory associated matching birthday problems large number examples many well known provided help reader feeling questions intuitive level c elsevier b v reserved revisit classic problem estimation binomial parameters parameters n p unknown start series illustrate fundamental difficuities problem specifically establish lack unbiased estimates essentially functions n p quantify badly biased sample maximum estimator n motivate present two new estimators n one new moment estimate bias correction sample maximum easy motivate compute jackknife second estimate frequently beats common estimates n simulations including carroll lombard estimate estimate promising end family estimates p specific one family compared presently common estimate maxi x bar improvements mean squared error often significant cases asymptotics derived one domain possible estimates truncated mle empirical bayes methods briefly discussed c elsevier b v reserved normalization bispectrum treated differently engineering signal processing standard statistical time series signal processing normalization treated matter definition matter choice convenience particular number investigators favor kim powers phys fluids bicoherence kim powers ieee trans plasma sci ps believe produces result guaranteed bounded zero one hence result easily interpretable fraction signal energy due quadratic coupling contribution wrong decisions obtained relying normalization always bounded one bicoherence depends resolution bandwidth sample bispectrum choice normalization solely matter definition choice empirical consequences term bicoherence spectrum misleading since really skewness spectrum statistical normalization presented measure quadratic coupling stationary random nonlinear processes finite dependence c elsevier b v reserved deals problem selecting good populations respect control k greater equal populations random variable associated population pi assumed positive valued density form f x theta c theta exp x theta h x unknown parameter theta k nonparametric empirical bayes approach used construct selection procedures performance procedures investigated studying regret bayes risks r n simple assumption prior g integraltheta g theta infinity nr n m m constant calculated explicitly result indicates rate o n easily obtained nonparametric procedures weak conditions c published elsevier b v microarrays new biotechnological devices permit simultaneous evaluation expression levels thousands genes one tissue samples develop new method identifying differentially expressed genes replicated cdna oligonucleotide microarray experiments method based nonparametric prediction interval computed order statistic control measurements applied sequentially series p replicate sets experimental measurements size n illustrate reasonable experiment wise false positive false negative rates attained practical number genes based manipulating order n p n method used identify gene expression levels associated pathological condition beyond chance expectations given large number genes tested illustrate method replicated gene expression data tumor normal colon tissues compare alternative approach based permutation tests c published elsevier b v multiple induction test procedure extends single induction test procedure proposed kodell chen biometrical j based work kokoska et al anticancer res introduced new procedure detect overall differences two groups well isolate differences distribution number induced tumors distribution times observation frequency latency procedure illustrated analysis data multiple dosing experiment likelihood ratio method testing frequency latency test compared logrank test negative binomial test test proposed dunson et al toxicol sci monte carlo simulation performed evaluate accuracy parameter estimates frequency latency procedure well type error rates frequency latency test logrank test negative binomial test c elsevier b v reserved necessary conditions balanced incomplete block design bibd satisfied bibd exists simple answer optimal design problem irregular bibd setting identification optimal d optimal design requires delicate interplay combinatorics optimality tools known theory extended giving comprehensive picture set potentially optimal designs affording better understanding relationship optimality simple combinatorial measures symmetry theory conjunction intricate search leads d optimal design d first known optimal design irregular bibd setting insight gained resolvable members d c elsevier b v reserved rather estimate population mean total sometimes estimate mean total subpopulation domain desired problems number units sample fall domain random variable causes complications usual frequentist approach give simple coherent noninformative bayesian approach domain estimation c elsevier b v reserved finite mixture model example non regular parametric family classical asymptotic cannot directly applied particular asymptotic properties likelihood ratio testing number subpopulations complicated difficult establish one approach found simplify asymptotic preserving power test modify likelihood function incorporating penalty term avoid boundary problems asymptotic properties likelihood ratio even difficult unknown structural parameter involved model application modified likelihood approach finite normal mixture models common unknown variance mixing components consider test homogeneous model versus mixture two components x distribution stochastic bound limiting distribution likelihood ratio statistic distribution stochastic upper bound limiting distribution modified likelihood ratio statistic small simulation suggests bounds relatively tight practically useful example genetics used illustrate technique c elsevier b v reserved experiment comparing two test treatments control treatment simultaneous confidence bounds amount test treatment differs control generally required experiment arranged block design optimal allocation experimental units within blocks individual test treatments control needs determined optimality criterion interest minimization expected average allowance eaa expected maximum allowance ema allowance represents plus minus attached point estimates product standard error critical value bounds eaa ema values provided one sided two sided confidence intervals search algorithm obtaining efficient designs described c elsevier b v reserved central question arises clinical trials many additional observations needed beyond originally planned earlier contributions considered continuous response assumes normal distribution treat portion interim stage internal pilot thus require unblinding certain randomized design interim binary data double blind clinical trials obtain closed form expressions effective level significance operating power specified alternative considered totally unblinded case numerical examples indicate significant increase level significance case blinded design contrary shih zhao statist med claimed type error probability control unblinded case c published elsevier b v discusses statistical inference proportional hazards model exists interval censoring survival time interest covariates j roy statist soc b encyclopedia biostatistics new york pp particular consider situations observations survival time doubly censored observations covariates interval censored inference regression parameters general estimating equation approach proposed proposed estimate parameter generalization maximum partial likelihood estimate right censored failure time data known exactly observed covariates statistical analysis failure time data new york asymptotic properties proposed estimate established finite sample properties investigated simulation c elsevier b v reserved problem estimating fixed effects parameters variance random effects variance components longitudinal mixed rasch model considered well known estimating parameters method maximum likelihood faces computational difficulties alternative propose generalized estimating equations approach approximations joint moments variables proposed estimators obtained consistent asymptotically normal illustrate usefulness method simulations analysis real data quality life c elsevier b v reserved flowgraph models useful wide variety systems engineering survival analysis problems especially useful analyzing time event data constructing corresponding bayes predictive distributions continuous time serni markov process defines transition times finite number states interest focuses estimating densities survival reliability hazard functions predictive distributions flowgraph models way presenting model associated method data analysis method illustrated data construction engineering project c elsevier b v reserved recent decades concept process capability emerged quantified prediction process adequacy capability indexes become popular means describing ability process produce products meet certain specifications indexes numerical measures process potential performance consider large sample estimation capability process index consider multi sample set random samples taken arbitrary populations propose shrinkage estimation strategies estimating population capability indexes classical estimator investigated competitor proposed estimators assess properties theoretically numerically riding theme shrinkage method powerful extension classical counterpart nonnormal populations c elsevier b v reserved consider variance estimation population totals ratios complex cross stratified surveys ultimate sampling weights random variables dependent first phase sampling new hybrid variance estimator dependent model based design based ideas introduced theoretical empirical justifications given proposed method handles well difficult aspects sample design c elsevier b v reserved consider comparison two instruments gold standard goal finding best one one agrees gold standard natural log mean squared deviation measure agreement present large sample two stage procedure good small sample properties differences paired measurements bivariate normal first stage sample size adequate application illustrate procedure dataset c elsevier b v reserved random life characterized nonnegative random variable x survival function sf f x p x x x greater equal associated life two notions life testing random remaining life age x random variable sf f x f x f x greater equal corresponding stationary renewal life equilibrium life denoted x whose sf isw f alpha mu integral x infinity f u du x greater equal mu e x assumed finite thus may used identify old age note unobservable studied x current investigation inequalities moments x derived ageing behavior x harmonic new better used expectation e x exists moment generating function x exists upper bound obtained moments inequalities derived ageing behavior test exponential belongs one several ageing classes c elsevier b v reserved models demasi et al adapted informatively censored failure times primary event times followup events proposed model treats informative censoring type risk competing risks setup inferences parameters model based standard partial likelihood theory simulation likelihood inference works well practice model demonstrated analyzing data waiting time bone marrow transplantation primary event time relapse death transplantation followup event leukemia patients residual inspection performed check adequacy model c elsevier b v reserved model assisted paradigm presently dominates survey sampling randomization based theory treated true approach inference models helpful choosing randomization based methods propose alternative theoretical paradigm model based inference conditions realized sample focus approach randomization based methods focus set hypothetical samples could drawn employed primarily protection model failure although choices made randomization assisted model based paradigm often little different recommended sarndal et al model assisted survey sampling springer new york motivation clearer moreover approach proposed variance estimation leads logically coherent treatment finite population small sample adjustments needed c elsevier b v reserved begin wold decomposition pc sequences rank pc sequence simply defined number non zero innovations occur period give simple examples sequences less full rank discuss prediction based finite infinite pasts c elsevier b v reserved presents infinite class algebras hermitian matrices size n x n n positive integer n prime number power prime number galois field gf n exists n obtain n separate hermitian algebras two mutually commute c elsevier b v reserved problem testing trend change failure rate great interest reliability survival analysis develop new test procedure testing whether failure rate changes trend one big advantage test neither change points proportions trend changes occur need known establish asymptotic null distribution proposed test statistic obtain asymptotic null critical values test applied performance new test procedure conduct monte carlo simulations compute powers test lognormal alternatives hjorth alternatives compare powers existing tests example presented illustrate application test c elsevier b v reserved linear model random intercept random slope considered assess degradation reliability component system case known variance covariance components model bias standard error se estimator time failure distribution examined taylor series expansion gaussian quadrature method simulation procedure simulation procedure considered variance covariance components estimated information practical situations used examine biases ses c elsevier b v reserved new strategy developed obtaining large sample efficient estimators finite dimensional parameters beta within semipafametric statistical models key idea maximize beta nonparametric log likelihood infinite dimensional nuisance parameter lambda replaced consistent preliminary estimator lambda beta kullback leibler minimizing value lambda beta fixed beta parametric submodel kullback leibler minimizer substituted lambda generally least favorable model extending severini wong ann statist establish efficiency estimator beta maximizing log likelihood lambda replaced fixed beta lambda beta theoretical specialized censored linear regression class semiparametric survival analysis regression models including proportional hazards models unobserved random effect frailty latter slud vonta scand j statist characterizing restricted kullback leibler information minimizers c elsevier b v reserved characterization spatial dependence component spatial modeling exercise reasons convenience model parsimony computational efficiency spatial covariance structure often assumed directional invariance properties reflection symmetry completely symmetry propose diagnostic tests reflection symmetry complete symmetry based two dimensional periodogram advantage basing tests periodogram rather sample semivariogram covariance function periodogram ordinates corresponding different frequencies asymptotically independent leading simpler distribution theory simulation two examples illustrate usefulness limitations proposed tests c elsevier b v reserved problem selecting largest treatment parameter provided better control simultaneously estimating selected treatment parameter general linear model considered decision theoretic bayes approach cases error variance known unknown included bayes decision rules derived noninformative normal priors bayes rules noninformative priors derived general loss function designs satisfy btib condition bechhofer tamhane technometrics unbalanced designs linear loss function adopted demonstrated via simulations simultaneous estimation selected treatment effect plays role correcting undesirable effect selection problem c elsevier b v reserved point treatment causal parameters defined marginal structural models estimated assumption unobserved confounders three estimators used g computation inverse probability treatment weighted iptw double robust dr estimator consistency properties iptw dr estimators known assumption treatment mechanism name experimental treatment assignment eta assumption first propose extend consistency property dr estimator redefining dr estimating function eta assumption violated simulations emulating point treatment illustrate practical consequences redefinition dr estimator iptw estimates biased finite sample size eta assumption practically theoretically violated whereas finite sample bias dr estimates negligible correct model specifications dr estimators known robust iptw estimators result implies robust g computation estimators point treatment motivated development methodology construct redefined dr estimators general missing data structure conclude illustration rationale general methodology causal inference point treatment c elsevier b v reserved independently identically distributed d univariate observations new estimation method maximum spacing msp method defined ranneby scand j statist independently cheng amin j roy statist soc b idea behind method described ranneby scand j statist approximate kullback leibler information contribution bounded present msp method extended multivariate observations since natural order relation r d d approach modified essentially two different approaches geometric probabilistic counterpart univariate case observation attach dirichlet cell geometrical correspondence obtained probabilistic counterpart would nearest neighbor balls random variable giving probability nearest neighbor ball distributed minimum n d uniformly distributed variables interval regardless dimension d approaches discussed present c elsevier b v reserved considers problem estimating error density distribution functions nonparametric regression models asymptotic distribution suitably standardized density estimator fixed point normal maximum suitably normalized deviation density estimator true density function case one sample set standardized residual empirical process uniformly close similarly standardized empirical process errors thus generalizes well known residual density estimators empirical process parametric regression models nonparametric regression models thereby enhancing domain applications c elsevier b v reserved critical values various tests based u detect possible change obtained permutations observations obtain approximations permutated u change null well exactly one change alternative used simulated critical values asymptotically valid null tests reject probability tending one alternative c elsevier b v reserved class goodness fit tests symmetric stable distribution proposed tests based weighted integral involving empirical characteristic function corresponding suitably centered data consistency tests investigated moment assumption decay weight function tends infinity limit obtained method applied real simulated data c elsevier b v reserved pickands estimator extreme value index generalized way includes previously known variants detailed asymptotic behavior estimators family serves determine optimally performing members given simple explicit formulas asymptotic variance maximum likelihood estimator generalized pareto model robust departures limiting generalized pareto model case convergence excess distribution limit slow simulation involving wide range distributions new estimators compare favorably maximum likelihood estimator c elsevier b v reserved smooth quantile estimator q p p based kernel k sequence bandwidth n sequence stationary strong mixing random variables minimal assumptions underlying distribution function f kernel k establish necessary sufficient conditions central limit theorem hold q p p extend central limit theorems ralescu sun j statist plarm inference sen j multivariate anal c elsevier b v reserved official file microdata must delivered external users difficult propose file missing values treated multiple imputations order overcome difficulty propose method single imputation qualitative data respect numerous constraints imputation balanced totals previously estimated editing rules respected imputation random totals affected imputation variance c elsevier b v reserved consider general class asymmetric univariate distributions depending real valued parameter includes entire family univariate symmetric distributions special case discuss connections proposal families skew distributions studied statistical key element construction families distributions stochastically represented product two independent random variables representation readily derive theoretical properties easy implement simulation schemes well extensions multivariate case statistical inference class based method moments maximum likelihood give special attention skew power exponential distribution cases like skew distribution considered statistical methods illustrated examples based real datasets c elsevier b v reserved propose new family life distributions generated elliptically contoured distribution density properties obtained explicit expressions density found large number specific elliptical distributions pearson type vii cauchy kotz type normal bessel laplace logistic c elsevier b v reserved behaviors naive bootstrap bayesian bootstrap clones designed approximate sampling distribution aalen johansen estimator non homogeneous censored markov chain approximations based bayesian bootstrap clones naive bootstrap first order asymptotically equivalent two bootstrap methods illustrated marketing example performance validated monte carlo experiment c elsevier b v reserved propose x harmonic divergences global measures accuracy approximation pi posterior density interest pi inequalities relate measures precision corresponding approximations posterior expectations practice divergences ought approximated somehow propose importance sampling type estimates based sample pi unlike familiar precision estimates based central limit type theorems monte carlo based pi proposal applied approximations obtained virtually every method available ii requires compute one measure accuracy reused assess precision approximations many posterior expectations iii since rationale external method used obtain pi avoids danger circular reasoning present instance markov chain monte carlo algorithms whereby validity approximation estimated precision depend convergence simulated chain practice may difficult assess c elsevier b v reserved considers tests autocorrelation among disturbances linear regression models expressed ratios quadratic forms tests general unbiased power even drop zero certain regressors spatial weight matrices whether happen easily diagnosed given regressors given spatial weights c elsevier b v reserved statistical researchers often want compare operating characteristics alternative test based simulation data points severe limitations current practice points way towards valid systematic methods main themes accuracy measures depend specific nominal size ii powers compared tests equal size receiver operating characteristic curves systematic method iii comparing accuracy measures competing tests essential take account typically correlation simply generally achieved via classical bootstrap iv relating test accuracy application conditions standard regression problem existing technology applied c elsevier b v reserved based type censored data exact confidence limit constructed reliability function two parameter exponential distribution concept generalized confidence interval due weerahandi j amer statist assoc interval exact e intended coverage confidence limit numerically obtained required computations simple straightforward approximation developed confidence limit performance numerically investigated numerical compared currently available approximation satisfactory terms providing intended coverage especially small samples c elsevier b v reserved common problem analysis variance testing heterogeneity different subsets full set k population means step procedure tests given subset p means rejecting homogeneity sets contain peritz gabriel closed procedure rejects homogeneity subset every partition k means includes subset includes rejected set begun gabriel closure algorithm reduces computations number tests still increases exponentially respect number complementary means m k p propose new algorithm tests m pairs adjacent ordered complementary sample means algorithm may used analyses variance test balanced unbalanced designs studentized ranges except extremely unbalanced designs seaman levin serlin proposed powerful closure criterion cannot exploit begun gabriel algorithm propose new algorithm case well c elsevier b v reserved motivated comparing sensitivities specificities two diagnostic tests paired design sample size small first derived edgeworth expansion studentized difference two binomial proportions paired data edgeworth expansion help us understand usual wald interval difference poor coverage performance small sample size based edgeworth expansion derived transformation based confidence interval difference new interval removes skewness edgeworth expansion new interval easy compute coverage probability converges nominal level rate o n numerical indicate new interval average coverage probability close nominal level average even sample sizes small numerical indicate new interval better average coverage accuracy best existing intervals finite sample sizes c elsevier b v reserved means utilizing auxiliary information surveys sample inclusion probabilities proportional given size values pips design preferably fixed sample size novel candidate context pareto pips sampling scheme derived limit considerations works degree approximation finite samples desired factual inclusion probabilities agree exactly turn leads estimator bias central topic derive conditions bias negligible practically useful information small sample behavior pareto pips best understanding gained numerical earlier investigations end limited allow general conclusions reports extensive numerical chief estimator bias negligible almost situations met survey practice c elsevier b v reserved balanced sampling design interesting property horvitz thompson estimators totals set balancing variables equal totals want estimate variance horvitz thompson estimators variables interest reduced function correlations balancing variables since hard derive analytic expression joint inclusion probabilities derive general approximation variance based residual technique approximation useful even particular case unequal probability sampling fixed sample size set numerical original methodology allows validate approximation c elsevier b v reserved uniformity utilized measure comparing factorial designs fang mukerjee biometrika fang et k fang f j hickernell h niederreiter eds monte carlo quasi monte carlo methods springer berlin found links among uniformity terms non uniformity measures orthogonality aberration regular symmetric factorials extend asymmetric factorials considering called wrap around l discrepancy evaluate uniformity factorials furthermore bound wrap around l discrepancy obtained asymmetric factorials two new ways construction factorial designs mixed levels proposed c elsevier b v reserved construct constrained approximate optimal designs maximizing criterion constraints approach problem transforming constrained optimization problem one maximizing three functions design weights simultaneously used class multiplicative algorithms indexed function f algorithms satisfy basic constraints design weights nonnegativity summation unity investigate techniques improving convergence rates means suitable choices function f c elsevier b v reserved considers construction d optimum designs kronecker product additive regression models errors heteroscedastic sufficient conditions given d optimum designs multi factor models built d optimum designs sub models single factor robustness included investigate design efficiencies change efficiency functions miss specified c elsevier b v reserved locally optimum non linear design problem chemical kinetic model investigate influence dispersion structure random observation errors design efficiency two kinds design determined model parameters error variance function interior designs boundary designs depend design range give exact criterion determining kind design arise illustrate qualitative difference two kinds design terms design locus equivalence theorem tabulate quantitative details designs range parameter values c elsevier b v reserved introduce scaled density models binary response data much reasonable traditional binary response models particular types binary response data maximum likelihood estimates new models seems model works well sets data considered optimum designs parameter estimation models found d d optimum designs independent parameters corresponding linear function dose level optimum designs simple functions scale parameter c elsevier b v reserved pairwise conditional score functions proposed explored us interpretation mantel haenszel estimator applicable deriving mantel haenszel type estimators exponential dispersion model multiple strata explicit forms estimating functions presented asymptotic relative efficiency examined cases exponential geometric distributions derivation numerical suggest derived estimators fairly robust efficiency mantel haenszel estimator c elsevier b v reserved robust slippage test problem k location parameters presence gross errors formulated point view huber robust test theory asymptotic model robust slippage test problem asymptotic level alpha slippage rank test based k linear rank constructed applying majorization methods asymptotic minimum power evaluated applying weak majorization methods slippage rank test asymptotically unbiased c elsevier b v reserved blum et al ann math statist test bivariate independence asymptotic equivalent hoeffding ann math statist test consistent dependence alternatives concise tabulation well considered approximation asymptotic percentiles null distribution given blum et al complete selection monte carlo percentiles samples size larger appears mudholkar wilding j roy statist soc neither tabulation adequate estimating p values test note moment based analogue classical wilson hilferty transformation obtain two transformations type n nb n hn transformations used construct compare gaussian scaled chi square approximation null distribution nb n approximations excellent accuracy gaussian approximation convenient portability c elsevier b v reserved wald test based approach power sample size calculations presented recently logistic poisson regression models asymptotic normal distribution maximum likelihood estimator applicable tests single parameter unlike previous procedures involving score likelihood ratio simple direct extension approach tests single parameter present method computing sample size statistical power employing discrepancy noncentral central chi square approximations distribution wald statistic unrestricted restricted parameter estimates respectively distinguishing features proposed approach accommodation tests multiple parameters flexibility covariate configurations generality overall response levels within framework generalized linear models general procedure illustrated special situations motivated research monte carlo simulation conducted assess compare accuracy existing approaches several model specifications covariate distributions c elsevier b v reserved develops adaptive non parametric modelings earthquake data non parametric techniques particularly suitable space time point processes must adapted deal non stationarity seismic phenomena mean changes spatial temporal pattern seismic occurrences set non parametric tests kernel density regression estimators proposed space time evolution earthquakes implied solutions respecting unidirectional nature time minimizing prediction errors naturally oriented forecasting extensive application northern california earthquake catalog ncec data set starting illustrates checks approach c elsevier b v reserved consider conditions parametric estimates intensity spatial temporal point process consistent although actual point process estimated may poisson estimate involving maximizing function corresponds exactly log likelihood process poisson consistent certain simple conditions second estimate based weighted least squares consistent quite similar assumptions conditions consistency simple easily verified examples provided illustrate extent consistent estimation may achieved special case point processes estimated fact poisson though examples explored well c elsevier b v reserved consider p dimensional location family symmetrical theta let c x alpha confidence set theta x theta less equal c theta x reasonable estimator theta traditionally confidence coefficient alpha data independent used report confidence c x improved confidence reports provided p greater equal related robinson ann statistic normal case discussed robinson ann statistic special case moreover admissibility p less equal present c elsevier b v reserved growing trend towards production hospital report cards hospitals acceptable mortality rates identified several commentators advocated bayesian methods health care report cards earlier research demonstrated poor concordance different bayesian methods current used monte carlo simulation methods examine reliability validity four different bayesian measures hospital performance estimates reliability different measures ranged estimates validity four measures ranged thus four measures hospital performance demonstrated reliability validity method moderate hypothesized validity due part limited sample sizes typically available hospital report cards c elsevier b v reserved establish connection two different topics e size biased sampling schemes bayesian updating mechanisms general class p discrete nonparametric priors exploiting connection able size biased sampling theory representations class particularly suitable applications inference problems derive new general posterior predictive distributions proper ties sample p potential approach illustrated via application dirichlet process investigation new class symmetric priors c elsevier b v reserved predictive density function g obtained multilevel model optimal minimizing criterion based kullback leibler divergence restricted class predictive densities thereby extending normal linear model j amer statist assoc based upon predictive density approach three prediction methods examined multilevel prior ols ols prediction method corresponds deriving predictive density separately group prior prediction method corresponds deriving predictive density entire model multilevel prediction method merely adjusts prior prediction method employing well known shrinkage estimator multilevel model estimation multilevel data simulated order assess performance three methods predictive intervals predictive mean square error pmse used assess adequacy prediction multilevel prediction method outperforms ols prior prediction methods somewhat surprising since ols prior prediction methods derived kullback leibler divergence criterion suggests restricted class predictive densities suggested levy perng normal linear model may need expanded multilevel model c elsevier b v reserved kernel density estimation used great success data may assumed generated independent identically distributed iid random variables methods theoretical iid data directly apply data stratified multistage samples present finite sample asymptotic properties modified density estimator introduced buskirk proceedings survey research methods section american statistical association pp bellhouse stafford statist sin estimator incorporates sampling weights kernel weights present regularity conditions lead sample estimator consistent asymptotically normal various modes inference used sample survey data introduce superpopulation structure model based inference allows population model reflect naturally occurring clustering estimator confidence bands derived sampling design illustrated data us national crime victimization survey us national health nutrition examination survey c elsevier b v reserved estimation scale parameter mixture models unknown location considered stein loss certain conditions inadmissibility usual estimator established exhibiting better estimators addition robust improvements found specified submodel original model applied mixtures normal distributions mixtures exponential distributions improved estimators variance normal distribution robust tinder scale mixture normals variance greater variance normal distribution particular stein ann inst statist math brewster zidek ann statist estimators obtained normal model robust model arbitrary degrees freedom double exponential model improved estimators variance distribution unknown arbitrary degrees freedom given addition improved estimators scale parameter multivariate lomax distribution arises certain mixture exponential distributions derived robustness zidek ann statist brewster ann statist estimators scale parameter exponential distribution established class modified lomax distributions c elsevier b v reserved considers one way random effects model assessing proportion workers whose mean exposures exceed occupational exposure limit based exposure measurements random sample workers testing interval estimation relevant parameter interest proposed exposure data unbalanced methods based generalized p value approach simplify ones krishnamoorthy mathews j agri biol environ statist data balanced sizes powers test evaluated numerically numerical proposed inferential procedures satisfactory even small samples illustrated practical examples c elsevier b v reserved consider problem model variable selection classical regression model based cross validation added penalty term penalizing overfitting weak conditions new criterion strongly consistent sense probability one large n criterion chooses smallest true model penalty function denoted c n depends sample size n chosen ensure consistency selection true model various choices c n suggested model selection particular choice c n based observed data makes random preserves consistency property improved performance fixed choice c n c elsevier b v reserved estimation p values robust tests linear regression model asymptotic distribution tests studied restrictive assumption errors known scale symmetric distribution since robust tests based robust regression estimates efron bootstrap presents number problems particular computationally expensive resistant outliers data words tails bootstrap distribution estimates obtained re sampling data may severely affected outliers adapt robust bootstrap ann statist bootstrapping mm estimators linear regression fixed designs http mathstat carleton ca similar tomatias pubs html problem method fast compute resistant outliers data asymptotically correct weak regularity assumptions robust bootstrap used obtain asymptotically correct computationally simple p value estimates simulation indicates tests whose p values estimated robust bootstrap better finite sample significance levels obtained asymptotic theory based symmetry assumption although focussed robust scores type tests directions robust diagnostics part springer new york approach applied robust tests example wald dispersion type discussed markatou et c elsevier b v reserved given two independent non degenerate positive random variables x y lukacs proved x x y x y independent x y gammally distributed scale parameter work properties bivariate gamma distribution studied certain regression version lukacs theorem given bivariate case furthermore characterization bivariate gamma distribution conditions constancy regression quadratic given c elsevier b v reserved properties scaled burr type x distribution given closed form expressions moments exist certain special cases upper bounds first moment given well approximation based bounds maximum likelihood estimation considered asymptotic properties estimators discussed d samples well types ii censoring extension multivariate burr type x distribution introduced c elsevier b v reserved two proofs problem title published incomplete note observe subtle errors proofs give new proof different approach c elsevier b v reserved accounting auxiliary covariate two phase sampling strategy order reduce experimental costs initially proposed cochran sampling techniques nd edition new york sampling techniques rd edition new york context sample surveys conniffe moran biometrics extended methodology estimation linear regression functions recently conniffe j econometrics causeur dhorne biometrics derived two phase sampling estimators linear regression function situation many auxiliary covariates available detailed distributional aspects estimators provided causcur multivariate context aims extension double sampling strategies monotone designs accounting differences costs subsets covariates particular maximum likelihood estimators provided asymptotic solutions optimal designs derived c elsevier b v reserved extends randomized response model presented christofides metrika case stratified sampling comparison application technique stratified simple random sampling presented addition model compared randomization technique stratified sampling kim warde j statist plann inference c elsevier b v reserved possible od exist addition classical techniques employ two new methods construction c elsevier b v reserved present new algorithms computing exact distributions p values quadratic sample distribution free kruskal wallis type algorithms presented terms generating functions algorithm works cases ties much faster existing algorithms moreover kruskal wallis type compute exact null distribution chacko shorack statistic c elsevier b v reserved integrals arbitrary borel measurable functions respect semiparametric estimator distribution function random censorship model based representation integrals similar one given stute kaplan meier integrals central limit theorem established generalizes corresponding result cheng lin estimator semiparametric integral estimator least efficient corresponding kaplan meier integral estimator terms asymptotic variance correct semiparametric model used furthermore necessary sufficient condition strict gain efficiency stated asymptotic result confirmed small simulation moderate sample sizes c elsevier b v reserved nonparametric regression smoothing parameter selected minimizing mean squared error mse based criterion spline smoothing one rewrite smooth estimation linear mixed model smoothing parameter appears priori variance spline basis coefficients allows employ maximum likelihood ml theory estimate smoothing parameter variance component relation two approaches illuminated penalized spline smoothing p spline suggested eilers marx statist sci theoretical empirical arguments given showing ml approach biased towards undersmoothing e chooses complex model compared mse result line classical spline smoothing even though asymptotic arguments different p spline smoothing finite dimensional basis employed classical spline smoothing basis grows sample size c elsevier b v reserved several distribution free bounds expected values l based sample possibly dependent nonidentically distributed random variables given case sample size random variable possibly dependent observations values set bounds extend papadatos case random sample size others new evaluations even sample size nonrandom applications presented bounds indicated c elsevier b v reserved diffusion processes x verifying stochastic differential equation dx dt b dw x x b considered standard wiener processes w problems testing hypotheses parameters analyzed stochastic process partially observed family test introduced basis renyi divergence measure asymptotic distributions obtained finish simulation given order compare powers introduced c elsevier b v reserved life testing n identical testing items placed test instead complete life testing n outcomes type ii censored life testing consisting first m outcomes usually employed although statistical analysis life testing based censored data less efficient complete life testing expected length censored life testing less complete life testing compare censored complete life testing suggest ways improve time saving efficiency instead complete life testing n outcomes put n n items test continues observe nth outcome censored life testing complete life testing containing number observations expected length censored life testing less complete life testing censored life testing may efficient complete life testing number observations c elsevier b v reserved general class priors dependence longitudinal temporal data settings parametric form often assumed place context idea embed priors parameters structure within richer flexible class priors priors contain standard objective priors structured unstructured dependence models special cases certain conditions parameterizations recommendations specific details regarding provided c elsevier b v reserved continuous time proportional trapping removal model estimation size animal population consideration disturbance non target animal studied maximum likelihood estimates corresponding standard errors targeted population derived large sample proper ties obtained martingale limit theory simulations conducted comparison done ignoring disturbance model example small mammal capture recapture deer mouse presented c elsevier b v reserved call bent cable model describe potential change point phenomena class bent cables includes commonly used broken stick bent cable without bend segment theory least squares ls estimation developed basic bent cable whose incoming outgoing linear phases slopes respectively joined smoothly quadratic bend conditions design given ensure regularity estimation problem despite non differentiability model first partial derivatives respect covariate model parameters conditions ls estimators consistent regardless zero positive true bend width ii asymptotically follow bivariate normal distribution underlying cable three segments latter case deviance statistic asymptotic chi squared distribution two degrees freedom c elsevier b v reserved based quadratic form group means consider two different approaches construct confidence interval among group variance one way random effects model unequal error variances one approach limits interval determined solving non linear equations whereas second approach bounds given explicitly correction terms convexity approaches improve primary intervals obtain intervals whose actual confidence coefficients closer nominal confidence coefficient means simulation improved confidence interval approach recommended practical c elsevier b v reserved polynomial regression measurement errors covariate latter supposed normally distributed one least three ways estimate unknown regression parameters one apply ordinary least squares ols model without regard measurement error one correct measurement error either correcting estimating equation als correcting mean variance functions dependent variable done conditioning observable error ridden counter part covariate sls ols biased two estimators consistent asymptotic covariance matrices thus relative efficiencies compared particular case small measurement error variance case appears als sls become almost equally efficient even differ noticeably ols c elsevier b v reserved arnold stahlecker considered estimation regression coefficients linear model relative squared error deterministic disturbances found explicit form minimax linear affine solution d problem generalize result arnold stahlecker proving decision rule d minimax class d possible estimators regression coefficients unrestricted d remains minimax d disturbances random mean vector zero identity covariance matrix c elsevier b v reserved two parameter generalized exponential distribution recently introduced gupta kundu austral new zealand j statist observed generalized exponential distribution used quite effectively analyze skewed data set alternative popular log normal distribution ratio maximized likelihoods choosing log normal generalized exponential distributions obtain asymptotic distributions logarithm ratio maximized likelihoods determine required sample size discriminate two distributions specified probability correct selection tolerance limit c published elsevier b v inverse gaussian family ig mu lambda versatile family modelling nonnegative right skewed data propose robust methods testing homogeneity scale like parameters lambda k independent ig populations order restrictions robustness procedures examined variety ig symmetric alternatives including lognormal recently introduced contaminated inverse gaussian populations inference procedures inverse gaussian scale like parameters properties exhibit striking similarities scale parameters normal distribution c elsevier b v reserved three families test testing nonadditivity loglinear models presented assumption either poisson multinomial product multinomial sampling new families based phi divergence measures standard method testing nonadditivity used e two stage tests procedure procedure parameters first estimated additive model estimates treated known constants second stage procedure test asymptotically chi squared generalize likelihood ratio test problem given christensen utts j statist plann inference example simulation included c elsevier b v reserved hajek ann math statist variance estimator used estimate variance horvitz thompson estimator chao sampling scheme chao biometrika implemented estimator simple implemented statistical packages consider numerical analytic method estimator used series simulations supports c elsevier b v reserved aspect paired comparison experiments decision form pairs advance collecting data weakness typical paired comparison experimental designs difficulty incorporating prior information particularly relevant design tournament schedules players games sports pairing methods prior information often ad hoc algorithms little formal basis problem pairing objects formalized bayesian optimal design assuming linear paired comparison model outcomes develop pairing method maximizes expected gain kullback leibler information prior posterior distribution optimal pairing determined combinatorial optimization method commonly used graph theoretic contexts discuss properties optimal pairing criterion method adaptive procedure pairing objects multiple times compare performance method simulated data random pairings system currently tournament chess c elsevier b v reserved robust estimator developed location scale parameters location scale family estimator defined minimizer minimum distance function measures distance ranked set sample empirical cumulative distribution function possibly misspecified target model estimator asymptotically normal robust efficiency respect competitors location estimator consistent within class symmetric distributions whereas scale estimator fisher consistent true target model considers optimal allocation procedure introduce bias due judgment error classification allocation procedure equivalent neyman allocation numerical efficiency comparison provided c elsevier b v reserved examines two different classes estimates population proportion based unbalanced rank set sample specifically two classes correspond maximum likelihood estimator mle weighted average wa estimate estimators asymptotically normal standard inference procedures still implemented furthermore used develop optimal allocation schemes estimators performances optimal estimators studied terms finite sample asymptotic relative efficiency general mle efficient wa estimate lastly practicality optimal sampling plans addressed illustrated via example c elsevier b v reserved present schemes allocation treatment groups presence prognostic factors allocations robust incorrectly specified regression responses possible heteroscedasticity assignment probabilities minimize asymptotic variance obtained certain conditions minimax respect asymptotic mean squared error well propose method sequentially modifying associated assignment rule address variance bias finite samples resulting scheme assessed simulation relative common competitors robust allocation schemes result significant decreases mean squared error fitted models biased minimal cost efficiency fact fitted models correct c elsevier b v reserved difference schemes cannot constructed known algebraic method developed sequential search algorithm makes larger difference schemes appending columns smaller difference schemes used known obscure difference scheme d apparently new difference schemes d d d d useful constructing orthogonal arrays c elsevier b v reserved
