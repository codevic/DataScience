brief overview design women health initiative whi clinical trial observational provided along summary postmenopausal hormone therapy clinical trial components since inception whi encountered number statistical issues methodology developments needed include measurement error modeling analysis procedures dietary physical activity assessment clinical trial monitoring methods treatments may affect multiple clinical outcomes either beneficially adversely design analysis procedures dimensional genomic proteomic data failure time data analysis procedures treatment group hazard ratios time dependent final topic seems resolving discrepancy whi clinical trial observational postmenopausal hormone therapy cardiovascular disease many standards medical care based demonstrated effects various treatment strategies processes unlike pharmacological treatments strategies processes necessarily subjected rigorous clinical trials benefit frequently assessed observational data evaluating influence medical processes patient outcomes risk adjustment issue center effect represents often overlooked consideration quality care tendency certain treatments processes vary one center another induced similarity outcomes within center well potential confounding center needs addressed within context risk adjustment addition center specific selection criteria treatment strategy vary respect patient risk considerations adequately separate within center effects treatment strategy across center effects relate center performance primary objective explore extend current methods dealing center confounding dichotomous outcomes primarily situation selection basis patient risk vary center center simulation compares several different analytic methods evidence importance considering confounding due risk center evaluating effectiveness process example examines effect early extubation bypass surgery presented fields medicine public health common application areal data models geographical patterns disease several measurements recorded spatial location example information p diseases population groups regions need consider multivariate areal data models order handle dependence among multivariate components well spatial dependence sites propose flexible new class generalized multivariate conditionally autoregressive gmcar models areal data enriches mcar class approach differs earlier ones directly specifies joint distribution multivariate markov random field mrf specification simpler conditional marginal models turn leads significant reduction computational burden hierarchical spatial random effect modeling posterior summaries computed markov chain monte carlo mcmc compare approach existing mcar models via simulation average mean square error amse convenient hierarchical model selection criterion deviance information criterion dic spiegelhalter et al journal royal statistical society series b offer real data application proposed gmcar approach models lung esophagus cancer death rates minnesota counties goal construct doubly robust dr estimators ignorable missing data causal inference models missing data model estimator dr remains consistent either necessarily model missingness mechanism model distribution complete data correctly specified observational data one never sure either missingness model complete data model correct perhaps best hoped dr estimator dr estimators contrast standard likelihood based nonaugmented inverse probability weighted estimators give analyst two chances instead one valid inference causal inference model estimator dr remains consistent either model treatment assignment mechanism model distribution counterfactual data correctly specified observational data one never sure model treatment assignment mechanism model counterfactual data correct inference based dr estimators improve upon previous approaches indeed present simulation finite sample performance dr estimators impressive theory would predict proposed method applied cardiovascular clinical trial extend mantel haenszel estimating function estimate intra cluster pairwise correlation main effects sparse clustered binary data propose composite likelihood approach estimating function approach analysis data proposed estimators consistent asymptotically normally distributed simulation two approaches comparable terms bias efficiency estimating equation approach computationally simpler analysis georgia blood pressure survey used illustration case cohort design longitudinal data consists subcohort sampled beginning followed repeatedly time case sample ascertained course although members subcohort may experience events period refer control cohort case sample random sample control cohort experienced least one event period different correlations among repeated observations individual accommodated two level random effects model design allows consistent estimation parameters estimable cohort design cost effective way effects covariates repeated observations relatively rare binary outcomes exposure assessment expensive extension case cohort design prentice biornetrika bidirectional case crossover design navidi biometrics simulation compares efficiency longitudinal case cohort design full cohort analysis certain situations efficiency obtained half sample size required full cohort analysis bootstrap method presented permits testing intra homogeneity presence unidentifiable nuisance parameters two level random effects model illustration apply design data ongoing childhood asthma propose nonparametric estimation preclinical duration distribution cancer based data randomized early detection trial cancer screening preclinical duration disease great interest better understanding natural history disease developing optimal screening strategies estimate sojourn time distribution nonparametrically first estimate distribution age onset preclinical disease nonparametrically data screening arm randomized screening trial distribution age onset clinical disease control arm randomized screening trial deconvolution two estimated distributions lead nonparametric estimate distribution gap time onset preclinical disease onset clinical disease illustrate methodology data randomized breast cancer screening trial develop graphical numerical methods checking adequacy generalized linear mixed models glmms methods based cumulative sums residuals covariates predicted values response variable assumed model asymptotic distributions stochastic processes approximated certain zero mean gaussian processes whose realizations generated monte carlo simulation observed process compared visually analytically number realizations simulated null distribution comparisons enable one assess objectively whether observed residual patterns reflect model misspecification random variation proposed methods particularly useful checking functional form covariate link function extensive simulation proposed goodness fit tests proper sizes sensitive model misspecification applications two medical lead improved models bivariate markov chain approach includes enduring long term ephemeral short term behavioral effects models capture recapture experiments proposed capture history animal modeled markov chain bivariate state space states determined capture status capture noncapture marking status marked unmarked framework conditional likelihood method used estimate population size transition probabilities classical behavioral model assumes enduring behavioral effect included special case bivariate markovian model another special case assumes ephemeral behavioral effect reduces univariate markov chain based capture noncapture status model ephemeral behavioral effect extended incorporate time effects model contrast extensions classical behavioral model parameters identifiable data set analyzed illustrate markovian models interpreting animals behavioral response simulation reported examine performance estimators regression applications categorical predictors interest often focuses comparing null homogeneity ordered alternative proposes bayesian approach addressing problem setting normal linear probit regression models regression coefficients assigned conditionally conjugate prior density consisting mixtures point masses truncated normal densities possibly unknown changepoint parameter included accommodate umbrella ordering two strategies prior elicitation considered bayesian bonferroni approach probability global null specified local hypotheses considered independent approach treats probabilities random single gibbs sampling chain used obtain posterior probabilities different hypotheses estimate regression coefficients predictive quantities either model averaging preferred methods applied data carcinogenesis develops model based approach clustering multivariate binary data attributes distinguish cluster rest population may depend cluster considered clustering approach based multivariate dirichlet process mixture model allows estimation number clusters cluster memberships cluster specific parameters unified way clustering approach applications analysis genomic abnormality data development different types tumors may depend presence certain abnormalities subsets locations along genome additionally mixture model nonparametric estimation scheme dependent sequences binary data accelerated longitudinal design ald individuals enter different points growth trajectory observed short time span relative entire time span interest ald data combined across independent units estimate overall population curve predictions individual patterns change modest extension work ruppert et al semiparametric regression cambridge university press develop computationally efficient procedure application longitudinal serniparametric methods ald sampling schemes compare balanced complete longitudinal designs alds berkeley growth data apply method longitudinal magnetic resonance imaging mri brain structure size volume measurements ongoing developmental potential applications extend beyond growth many fields cost feasibility constraints impose restrictions sample size numbers timings repeated measurements across motivated women health aging information physical functioning recorded along death information group elderly women focus determining whether difficulties daily living tasks accompanied mortality rate end two parameter logistic regression model used modeling binary questionnaire data assuming underlying continuous latent variable difficulty daily living cox model used survival information continuous latent variable included explanatory variable along observed variables parameters estimated maximizing likelihood joint distribution items time event information addition presenting new statistical model illustrates model real data setting addresses practical issues model building diagnostics parameter interpretation extends previous probability models periodic breast cancer screening examinations specific aim statistical inference age dependence sensitivity transition probability disease free preclinical state setting periodic screening program cohort initially asymptomatic women undergo sequence breast cancer screening exams age covariate estimation screening sensitivity transition probability simultaneously frequentist point view within bayesian framework apply method health insurance plan greater new york female breast cancer give age dependent sensitivity transition probability density estimates inferential methodology develop applicable analyzing modalities early detection types progressive chronic diseases recurring objective longitudinal aging longevity investigation relationship age death current values longitudinal covariate trajectory quantifies reproductive behavioral activity propose novel technique predicting age death distributions situations entire covariate history included predictor predictor trajectories current time represented time varying functional principal component scores continuously updated time progresses considered time varying predictor variables entered class time varying functional regression models propose biodemographic data methods applied obtain predictions age death estimates remaining lifetime distributions including estimates quantiles prediction intervals remaining lifetime estimates predictions obtained individual based observed behavioral trajectories include dimension reduction step implemented projecting single index proposed techniques illustrated data longitudinal daily egg laying female medflies predicting remaining lifetime age death distributions individual event histories observed current time existing distributions modeling fetal response data developmental toxicology beta binomial distribution tendency inflating probability malformed fetuses hence understating risk least one malformed fetus within litter opposed shared probability extra binomial model advocate shared response model allows random number fetuses within litter share common response explicit formula given probability function graphical plots suggest suffer problem assigning much probability event malformed fetuses em algorithm used estimate model parameters simulation em estimates nearly unbiased associated confidence intervals based usual standard error estimates coverage close nominal level simulation suggest shared response model estimates marginal malformation probabilities robust misspecification distributional form estimates intralitter correlation litter level probability least one malformed fetus proposed model fitted set data u national toxicology program dose response relationship fit based shared response distribution superior based beta binomial comparable based recently proposed q power distribution kuk applied advantage shared response model q power distribution interpretable extended easily multivariate case illustrate bivariate shared response model fitted fetal response data involving visceral skeletal malformation semiparametric estimation procedure proposed model capture recapture data aim estimating population size closed population individuals covariates possibly time dependent missing noncaptured times may measured error set estimating equations ees based covariate process capture recapture data constructed estimate relevant parameters population size ees solved algorithm similar em algorithm simulation proposed procedures work better naive estimate cases even better ideal estimates true values covariates available captured entire experimental period apply method capture recapture experiment bird species prinia flaviventris hong kong statistical modeling framework described estimating abundances spatially distinct subpopulations animals surveyed removal sampling illustrate framework hierarchical models developed poisson negative binomial distributions model variation abundance among subpopulations beta distribution model variation capture probabilities models fitted removal counts observed survey federally endangered fish species resulting estimates abundance similar better precision computed conventional approach analyzing removal counts subpopulation separately extension hierarchical models include spatial covariates abundance straightforward may used identify features animal habitat predict abundance animals unsampled locations randomized clinical trial statistic measures proportion treatment effect primary clinical outcome explained treatment effect surrogate outcome useful concept investigate whether statistic proposed estimate proportion given causal interpretation defined models counterfactual variables situation binary surrogate outcome variables two counterfactual models considered include concept proportion treatment effect acts surrogate general statistic equal either two proportions counterfactual models substantially different conditions given statistic equal counterfactual model proportions randomized clinical trial potential surrogate endpoints undertaken scientific context context naturally place constraints parameters counterfactual model conducted simulation experiment investigate impact constraints relationship proportion explained pe statistic counterfactual model proportions found observable constraints little impact agreement statistic counterfactual model proportions whereas unobservable constraints could lead agreement model binary trials based bivariate generalization poisson process number successes number trials transition rates dependent accumulating numbers successes trials used reanalyze recently published data zhu eickhoff kaiser biometrics modeling admits alternative distributions numbers trials numbers successes conditional number trials generalize poisson binomial distributions without restrictions apparent bet binomial poisson mixed modeling zhu et al quite marked differences analysis described zhu et al apparent wang ke brown biometrics developed smoothing based approach modeling circadian rhythms random effects approach flexible fixed random covariates affect amplitude phase shift nonparametrically smoothed periodic function motivating approach wang et al stated simple sinusoidal function restrictive addition stated although adding harmonics improve fit difficult decide many harmonics include model difficult interpret disagree notion harmonic models cannot useful tool modeling longitudinal circadian rhythm data note nonlinear mixed models harmonic terms allow simple flexible alternative wang et al approach choose number harmonics penalized likelihood flexibly model circadian rhythms estimate effect covariates rhythms fit harmonic models cortisol circadian rhythm data presented wang et al illustrate approach furthermore evaluate properties procedure small simulation proposed parametric approach alternative wang et al semiparametric approach added advantage easy implement statistical software packages several authors addressed problem calculating sample size matched casecontrol dichotomous exposure approach parker bregman biometrics view one satisfactory since requires specification quantities often easily available investigator recommended implementation involves computational approximation approximation performs poorly extreme situations easily replaced exact calculation radio tags detectability often used capture recapture key assumption radio tags cease functioning radio tag failure end lead underestimates survival rates develop model incorporate secondary radio tag failure data model applied chinook smolts oncorhynchus tshawytscha columbia river washington estimates fish survival model much larger standard cormack jolly seber analysis bayes factors comparing two competing hypotheses often estimated constructing markov chain monte carlo mcmc sampler explore joint space hypotheses obtain efficient bayes factor estimates carlin chib journal royal statistical society series b suggest adjusting prior odds competing hypotheses posterior odds approximately one estimating bayes factor simple division byproduct one often produces several independent mcmc chains one actually used estimation extend approach incorporate output multiple chains proposing three statistical models first assumes independent sampler draws models indicator function logistic regression various choices prior odds two complex models relax independence assumption allowing lag dependence within mcmc output models allow us estimate uncertainty bayes factor calculation fully several different mcmc chains even prior odds hypotheses vary chain chain apply methods calculate bayes factors tests monophyly two phylogenetic examples first example explores relationship unknown pathogen set known pathogens identification unknown monophyletic relationship may affect antibiotic choice clinical setting second example focuses hiv recombination detection potential clinical application types analyses must completed efficiently possible observations multiple response variables across space time occur often environmental ecological compared purely spatial models single response variable exponential family distributions fewer statistical tools available multiple response variables necessarily gaussian exception common factor model developed multivariate spatial data wang wall biostatistics purpose extend multivariate space model develop flexible class generalized linear latent variable models multivariate spatial temporal data statistical inference maximum likelihood estimates standard deviations obtained monte carlo em algorithm novel way automatically adjust monte carlo sample size facilitates convergence monte carlo em algorithm methodology illustrated ecological red pine trees response bark beetle challenges forest stand wisconsin robust methods useful making reliable statistical inferences small deviations model assumptions widely used method generalized estimating equations robustified replacing standardized residuals m residuals pearson residuals assumed unbiased zero parameter estimators robust approach asymptotically biased error distributions symmetric propose distribution free method correcting bias extensive numerical proposed method reduce bias substantially examples given illustration derive semiparametric methods estimating testing treatment effects censored recurrent event data available multiple periods methods based estimating functions motivated working mixed poisson assumption conditioning eliminate specific random effects robust pseudoscore test obtained via sandwich variance estimation relative efficiency conditional versus marginal analyses assessed analytically mixed time homogeneous poisson model robustness empirical power semiparametric approach assessed simulation adaptations handle recurrent events arising crossover trials described methods applied data two period crossover trial patients bronchial asthma presence covariate measurement error proportional hazards model several functional modeling methods proposed include conditional score estimator tsiatis davidian biometrika parametric correction estimator nakamura biometrics nonparametric correction estimator huang wang journal american statistical association order weaker assumptions error although consistent suffers potential difficulties small samples substantial measurement error upon noting conditional score parametric correction estimators asymptotically equivalent case normal error investigate relative finite sample performance discover former superior finding motivates general refinement approach parametric nonparametric correction methods refined correction estimators asymptotically equivalent standard counterparts improved numerical properties perform better standard estimates exist outliers simulation application hiv clinical trial presented research sequentially monitors paired survival differences new class nonparametric tests based functionals standardized paired weighted log rank pwlr standardized paired weighted kaplan meier pwkm tests trial tests may alternately assume role extreme statistic monitoring pemax maximum absolute values standardized pwlr pwkm one combines advantages rank based non rb paired testing paradigms simulations monitoring treatment differences pemax maintains type error nearly powerful advantageous two tests proportional hazards ph well non ph situations hence pemax preserves power robustly individually monitored pwlr pwkm maintaining reasonably simple approach design analysis example early treatment diabetic retinopathy etdrs given observational time dependent treatment time dependent covariates desirable balance distribution covariates every time point time dependent propensity score based cox proportional hazards model proposed used risk set matching matching propensity score achieve balanced distribution covariates treated control groups optimal matching various designs conducted compared surgical treatment cystoscopy hydrodistention given response chronic bladder disease interstitial cystitis simulation suggest statistical analysis matching outperforms analysis without matching terms point interval estimations general class multivariate life distributions considered analyzing failure time clustered data censoring multiple modes failure conditional cluster specific quantities joint distribution failure time event indicator expressed mixture distribution time failure due certain type specific cause failure type distribution assume marginal probabilities various failure types logistic functions covariates cluster specific quantities unknown distribution causes frailty unknown frailty distribution modeled nonparametrically dirichlet process semiparametric setup hybrid method estimation proposed based d weighted chinese restaurant algorithm helps us generate observations predictive distribution frailty monte carlo ecm algorithm plays vital role obtaining estimates parameters assess extent effects causal factors failures certain type simulation conducted consistency methodology proposed methodology used analyze real data set hiv infection cohort female prostitutes senegal analysis data dose response long divided according two major strategies multiple comparison procedures model based approaches model based approaches assume functional relationship response dose taken quantitative factor according prespecified parametric model fitted model used estimate adequate dose achieve desired response validity conclusions highly depend correct choice priori unknown dose response model multiple comparison procedures regard dose qualitative factor assumptions underlying dose response model primary goal often identify minimum effective dose statistically significant produces relevant biological effect one approach evaluate significance contrasts different dose levels preserving family wise error rate procedures relatively robust inference confined selection target dose among dose levels investigation describe unified strategy analysis data dose response combines multiple comparison modeling techniques assume existence several candidate parametric models multiple comparison techniques choose one likely represent true underlying dose response curve preserving family wise error rate selected model used inference adequate doses continual reassessment method crm dose finding design dynamic sequential updating scheme common dynamic schemes method estimates current dose level corresponding target percentile experimentation estimate based included continual reevaluation made possible simple model stands neither crm dynamic schemes allow correct estimation target percentile based retrospective data apart exceptional situation simplified model exactly generates observations focus specific issue retrospective analysis data generated arbitrary mechanism subsequently analyzed via continual reassessment method done consistently proposed methodology restricted particular design applicable sequential updating scheme dose levels associated percentiles via model inversion neurotoxic effects chemical agents often investigated controlled rodents multiple binary continuous endpoints routinely collected one goal conduct quantitative risk assessment determine safe dose levels face two major challenges continuous outcomes first characterizing risk defining benchmark dose difficult usually associated adverse binary event risk clearly definable quantal settings presence absence event finding similar probability scale continuous outcomes less clear often adverse event defined continuous outcomes value specified cutoff level distribution assumed normal log normal second continuous outcomes traditionally analyzed separately recent advocates multiple outcomes assess risk propose method modeling quantitative risk assessment bivariate continuous outcomes address difficulties extending existing percentile regression methods model likelihood based allows separate dose response models outcome accounting bivariate correlation overall characterization risk approach estimation benchmark dose analogous quantal data without need specify arbitrary cutoff values illustrate methods data neurotoxicity triethyl tin exposure rats propose bayesian methods estimating parameters generalized linear models glms nonignorably missing covariate data improper uniform priors used regression coefficients phi multinomial selection model missing data mechanism resulting joint posterior always improper missing covariates discrete intercept included selection model missing data mechanism ii least one covariates continuous unbounded impropriety result regardless whether proper improper priors specified regression parameters beta glm parameters alpha covariate distribution overcome problem propose novel class proper priors regression coefficients phi selection model missing data mechanism priors robust computationally attractive sense inferences beta sensitive choice hyperparameters prior phi facilitate gibbs sampling scheme leads accelerated convergence addition extend model assessment criterion chen dey ibrahim biometrika called weighted l measure glms missing data problems well extend deviance information criterion dic spiegelhalter et al journal royal statistical society b assessing whether missing data mechanism ignorable nonignorable novel markov chain monte carlo sampling algorithm developed carrying posterior computation several simulations given investigate performance proposed bayesian criteria well sensitivity prior specification real datasets melanoma cancer clinical trial liver cancer presented illustrate proposed methods concerned bayesian estimation stochastic rate constants context dynamic models intracellular processes underlying discrete stochastic kinetic model replaced diffusion approximation stochastic differential equation approach white noise term models stochastic behavior model identified equispaced time course data estimation framework involves introduction m latent data points every pair observations mcmc methods used sample posterior distribution latent process model parameters methodology applied estimation parameters prokaryotic autoregulatory gene network statistical methods detection genes influencing quantitative traits aid genetic markers well developed normally distributed fully observed phenotypes many experiments concerned failure time phenotypes skewed distributions usually censoring random loss follow failures competing causes limited duration experiment develop semiparametric statistical methods mapping quantitative trait loci qtls based censored failure time phenotypes formulate effects qtl genotype failure time cox journal royal statistical society series b proportional hazards model derive efficient likelihood based inference procedures addition assess statistical significance searching several regions entire genome qtls extensive simulation proposed methods perform well practical situations applications two animal provided healthy middle aged women precautionary mammograms trauma surgeons popular triss score predict likelihood patient survival examples questions confronting us decide whether yes prediction order trust prediction must valuable would best guess future absence prediction calculating value means identifying loss prediction err examining past performance prediction respect loss statistical test developed predictions pass test said skill skillful predictions used graphical numerical methods identify skill demonstrated usefulness mammograms explored construct three smooth goodness fit tests testing zero inflated poisson zip distribution general smooth alternatives sense neyman apply tests data set previously claimed zip distributed zip good model describe data rejection null zip individual components test statistic directly related interpretable parameters smooth model may used gain insight alternative distribution develops methods stratified analyses additive multiplicative causal effect binary outcomes randomized trials noncompliance methods based weighted estimating function unbiased estimating function randomization stratum known weights used derived estimator natural extension instrumental variable estimator stratified analyses test based confidence limits solutions quadratic equation causal parameter optimal weights maximize asymptotic efficiency incorporate variability compliance aspects across strata assessment based asymptotic relative efficiency substantial enhancement efficiency gained optimal weights instead conventional ones incorporate variability compliance aspects across strata application field trial coronary heart disease provided covariate measurement error regression typically assumed act additive multiplicative manner true covariate value assumption hold measurement error sleep disordered breathing sdb wisconsin sleep cohort wscs true covariate severity sdb observed surrogate number breathing pauses per unit time sleep nonnegative semicontinuous distribution point mass zero propose latent variable measurement error model error structure situation implement linear mixed model estimation procedure similar regression calibration involves distributional assumption latent variable modeling model fitting strategies explored illustrated example wscs note clarifies conditions naive analysis misclassified predictor induce bias regression coefficients perfectly measured predictors model apparent discrepancy previous result measurement error continuous variable linear regression resolved similar linear setting misclassification even related predictors induces bias coefficients perfectly measured predictors unless misclassified variable perfectly measured predictors independent conditional asymptotic biases discussed case linear regression explored numerically example relating birth weight weight smoking status mother consider estimation generalized linear mixed models glmm longitudinal data informative dropouts time unit drops time varying covariates often unobserved addition missing outcome existing informative dropout models typically require covariates completely observed assumption realistic presence time varying covariates first asymptotic bias would result applying existing methods missing time varying covariates handled naive approaches include baseline values carrying forward last observation assuming missing data ignorable asymptotic bias analysis naive approaches yield inconsistent estimators model parameters next propose selection transition model allows covariates missing addition outcome variable time dropout em algorithm used inference proposed model data longitudinal human immunodeficiency virus hiv infected women used illustrate methodology adjusted attributable risk ar proportion diseased individuals population due exposure consider estimates adjusted ar based odds ratios logistic regression adjust confounding influence function methods used survey sampling applied obtain simple easily programmable expressions estimating variance ar variance estimators applied data case control cross sectional cohort without frequency individual matching sample designs samples range simple random samples sample weighted multistage stratified cluster samples like used national household surveys variance estimation ar illustrated weighted stratified multistage clustered cross sectional childhood asthma third national health examination survey nhanes iii ii frequency matched case control melanoma skin cancer melville welsh biometrics consider approach line transect sampling separate calibration estimate detection function g present simulation contrasting poor traditional estimator labeled buckland estimator referenced buckland et al distance sampling estimating abundance biological populations poor buckland estimator explained following observations estimator designated untruncated distance data applied melville welsh truncated distance data ii distance data pooled across transects contrary standard practice iii bias estimator evaluated respect fixed rather randomized grid transect lines elaborate points traditional methods perform expectation applied correctly emphasize estimator labeled buckland estimator melville welsh estimator recommended buckland et al practical survey applications longitudinal clustered situations often binary continuous response variables observed need modeled together recent publication dunson chen harry biometrics dch propose bayesian approach joint modeling cluster size binary continuous subunit specific outcomes illustrate approach developmental toxicity data example note standard software proc nlmixed sas used obtain maximum likelihood estimates alternative parameterization model single cluster level factor considered dch example suggest general model additional cluster level random effects better fit data set apparent discrepancy estimates obtained dch estimates obtained earlier catalano ryan journal american statistical association resolved issue bias inferences concerning dose effect cluster size ignored discussed maximum likelihood approach considered herein applicable general situations multiple clustered longitudinally measured outcomes different type require prior specification extensive programming dorazio royle biometrics investigated behavior three mixture models closed population capture recapture analysis presence individual heterogeneity capture probability simulations beta binomial distribution analyses beta binomial logit normal finite mixture latent class models response simulations many different distributions give broader picture relative value beta binomial finite mixture models preliminary insights situations models useful populations many north american landbirds showing signs declining gathering information breeding productivity allows early detection unhealthy populations helps develop good habitat management practices performance bayesian model biometrics age specific nest survival rates irregular visits estimates satisfactory except age one survival rate usually days skipped two visits serious underestimation age one survival rate investigated problem developed three approaches adjust underestimation bias simulation three approaches significantly improve estimation age one survival rate several new methods account noncompliance missing data randomized trials proposed dual effects noncompliance nonresponse rarely dealt simultaneously construct maximum likelihood estimator mle causal effect treatment assignment two armed randomized trial assuming none treatment noncompliance allowing subsequent nonresponse em algorithm used parameter estimation likelihood procedure relies latent compliance state covariate describes behavior possible treatment assignments characterizes missing data mechanism frangakis rubin biometrika simulated data mle normal outcomes compares favorably method moments mom standard intention treat itt estimators normal nonnormal data departures latent ignorability compound exclusion restriction assumptions illustrate methods data trial compare efficacy two antipsychotics adults refractory schizophrenia phase clinical trials designed determine maximum tolerated dose mtd one initial administration treatment course cytotoxic experimental agent toxicity usually defined indicator whether one particular adverse events occur within short time period start therapy physicians often administer agent patient repeatedly monitor long term toxicity due cumulative effects propose new method settings based time toxicity rather binary outcome goal determine maximum tolerated schedule mts rather conventional mtd model method account patients entire sequence administrations overall hazard toxicity modeled sum sequence hazards associated one administration data monitoring decision making done continuously throughout trial illustrate method allogeneic bone marrow transplantation bmt trial determine long recombinant human growth factor cart administered prophylaxis acute graft versus host disease agvhd present simulation context trial propose bayesian approach phase ii dose finding oncology trials jointly modeling binary toxicity outcome continuous biomarker expression outcome apply method clinical trial new gene therapy bladder cancer patients trial biomarker expression indicates biological activity new therapy ethical reasons trial conducted sequentially dose successive patient chosen toxicity activity data patients previously treated trial modeling framework naturally incorporates correlation binary toxicity continuous activity outcome via latent gaussian variable dose escalation de escalation decision rules based posterior distributions toxicity activity flexible state space model used relate activity outcome dose extensive simulation design reliably chooses preferred dose toxicity expression outcomes various clinical scenarios propose bayesian approach phase ii dose finding oncology trials jointly modeling binary toxicity outcome continuous biomarker expression outcome apply method clinical trial new gene therapy bladder cancer patients trial biomarker expression indicates biological activity new therapy ethical reasons trial conducted sequentially dose successive patient chosen toxicity activity data patients previously treated trial modeling framework naturally incorporates correlation binary toxicity continuous activity outcome via latent gaussian variable dose escalation de escalation decision rules based posterior distributions toxicity activity flexible state space model used relate activity outcome dose extensive simulation design reliably chooses preferred dose toxicity expression outcomes various clinical scenarios consider clinical sample size reestimation based unblinded variance estimation interim point sample size determined flexible way usual variance estimator end trial biased derive sharp bounds bias bounds quite simple form help decision bias negligible actual correction done exact formula bias provided discuss possibilities get rid bias least reduce bias substantially purpose propose certain additive correction bias see example significance level test controlled additive correction used clinical trial designs involving correlated data often arise biomedical research intracluster correlation needs taken account ensure validity sample size power calculations contrast fixed sample designs propose flexible trial design adaptive monitoring inference procedures total sample size predetermined adaptively reestimated observed data via systematic mechanism final inference based weighted average block wise test generalized estimating equations weight block depends cumulated data ongoing trial significant treatment effects devised stopping rule allows early termination trial acceptance null proposed design updates information regarding effect size within cluster correlation based cumulated data order achieve desired power estimation parameter interest confidence interval proposed conduct simulation examine operating characteristics illustrate proposed method example construct interpretable prognostic rules based sequence box shaped regions predictor space indexed fraction patients prognostic group addition method used building block construct general prognostic rules based unions boxes even tool multiple prognostic groups simulations used properties new method compare constructing prognostic groups based regression trees linear proportional hazards ph models consider example based data several completed clinical trials patients multiple myeloma common longitudinal collect information time key clinical event death measure markers patient health multiple follow times one approach joint analysis survival repeated measures data adopts time varying covariate regression model event time hazard standard approach instantaneous risk death time specified possibly semiparametric function covariate information accrued time manuscript decouple time scale modeling hazard time scale accrual available longitudinal covariate information specifically propose class models condition covariate information time specifies conditional hazard times approach parallels partly conditional models proposed pepe couper journal american statistical association pure repeated measures applications estimation based estimating equations applied clusters data formed creation derived survival times measure time measurement covariates end follow patient follow may terminated either occurrence event censoring proposed methods allow flexible characterization association longitudinal covariate process survival time facilitate direct prediction survival probabilities time varying covariate setting considers statistical models two different types events diagnosis disease remission disease occur alternately time observed right censoring propose nonparametric estimators joint distribution bivariate recurrence times marginal distribution first recurrence time general marginal distribution second recurrence time cannot estimated due identifiability problem conditional distribution second recurrence time estimated nonparametrically statistical methods developed estimate joint distribution bivariate recurrence times based data first pair censored bivariate recurrence times methods inefficient model considered recurrence times orders used asymptotic properties proposed estimators established numerical estimators perform well practical sample sizes apply proposed method south verona italy psychiatric case register pcr data set illustration methods theory propose new class survival models naturally links family proper improper population survival functions models resulting improper survival functions often referred cure rate models class regression models formulated box cox transformation population hazard function proper density function adding extra transformation parameter cure rate model able generate models zero cure rate thus leading proper population survival function graphical illustration behavior influence transformation parameter regression model provided consider bayesian approach motivated complexity model prior specification needs accommodate parameter constraints due nonnegativity survival function moreover likelihood function involves complicated integral survival function may analytical closed form thus makes implementation gibbs sampling difficult propose efficient markov chain monte carlo computational scheme based gaussian quadrature proposed method illustrated example involving melanoma clinical trial approach generalized estimating equations gee based framework generalized linear models allows specification working matrix modeling within correlations variance often assumed known function mean investigates impacts misspecifying variance function estimators mean parameters quantitative responses numerical indicate correct specification variance function improve estimation efficiency even correlation structure misspecified misspecification variance function impacts much estimators within cluster covariates cluster level covariates variance function misspecified correct choice correlation structure may necessarily improve estimation efficiency illustrate impacts different variance functions real data set cow growth fish bred tanks ponds cannot easily tagged individually parentage individual may determined dna fingerprinting sufficiently expensive large numbers cannot fingerprinted measurement objective trait made much larger sample relatively cheaply deals experimental designs selecting individuals fingerprinted estimation individual family breeding values general setup estimates genetic effects regarded fixed random fixed effects due known regressors family effects well estimated even small numbers fingerprinted provided individuals extreme phenotypes significant tool ecological species accumulation curve collector curve graph expected number detected species function sampling effort problem estimating species accumulation curve based empirical data set arising quadrat sampling studied nonparametric binomial mixture model estimating species accumulation curve independent unknown number species includes estimating number species limiting case purpose interpolation moment based estimators associated asymptotic confidence intervals developed several points view likelihood based procedure developed purpose extrapolation associated bootstrap confidence intervals proposed methods illustrated ecological data sets capture recapture models originally developed account encounter probabilities less free ranging animal populations nowadays models deal movement animals different locations used transitions different states estimate transitions states account uncertainty state assignment present extension multievent models incorporate uncertainty multievent models belong family hidden markov models memory model next state location influenced previous state occupied fully treated within framework multievent models interest analysis series experiments repeated several environments set plant varieties suppose experiments multi environment variety trials conducted resolvable incomplete block ib designs following randomization approach adopted calinski kageyama lecture notes two models analyzing trial data considered one derived complete additivity assumption takes account possible different responses varieties variable environmental conditions analysis first standard model answers questions related performance individual varieties different environments considered general second model purpose devise interesting parameter estimation testing procedures realistic model application illustrated thorough analysis set data winter wheat series trials malaria remains major epidemiologic problem many developing countries malaria defined presence parasites symptoms usually fever due parasites endemic areas individual may symptoms attributable either malaria causes clinical viewpoint correctly diagnose individual developed symptoms appropriate treatments given epidemiologic economic viewpoint determine proportion malaria affected cases individuals symptoms policies intervention program developed symptoms developed individual diagnosis malaria based analysis parasite levels blood samples even blood test conclusive endemic areas many healthy individuals parasites blood slides data type viewed coming mixture distribution components corresponding malaria nonmalaria cases unique feature type data fact proportion nonmalaria cases zero parasite levels one component distributions mixture distribution propose semiparametric likelihood approach estimating proportion clinical malaria parasite level data group individuals symptoms approach assumes density ratio parasite levels clinical malaria nonclinical malaria cases modeled logistic model empirical likelihood combine zero nonzero data maximum semiparametric likelihood estimate efficient existing nonparametric estimates frequencies zero nonzero data hand robust fully parametric maximum likelihood estimate assumes parametric model nonzero data simulation performance proposed method satisfactory proposed method used analyze data malaria survey carried tanzania selective sampling cost effective design mapping quantitative trait loci qtls unified framework naturally combines two complementary sources linkage information data proposed mapping qtls selected pedigrees score detecting linkage introduced single locus models univariate bivariate phenotypes two locus epistasis models computer implementation methods single locus univariate phenotype models provided nuclear families arbitrary number sibs freely available advent complete genetic linkage maps dna markers made systematic mapping quantitative trait loci qtl experimental organisms feasible method multiple interval mapping appropriate way mapping qtl genetic markers efficient algorithms computation involved remain developed full em algorithm simultaneous computation mles qtl effects positions developed em based formulas derived computing observed fisher information matrix full em algorithm compared ecm algorithm developed kao zeng biometrics validity inverted observed fisher information matrix estimate variance matrix mles demonstrated simulation work addresses issues around physical maps particular circular genomes overlapping relationship two fragments obtained applying two different restriction enzymes separately classified nonoverlapping partial overlapping total overlapping double partial overlapping appear particular situation taking account dna fragment lengths assumption left hand endpoints two restriction fragments independent random variables uniform distribution along circular genome present expressions prior probabilities events information combined hybridization data via bayes theorem order evaluate corresponding posterior probabilities additionally explore sensitivity analysis quantify effect length variation dna microarrays conjunction statistical models may help gain deeper understanding molecular basis specific diseases intense area research concerned identification genes related particular phenotypes technology various sources error may lead expression readings substantially different true transcript levels methods microarray data analysis accounted measurement error substantial way purpose investigation describe bayesian error variable model analysis microarray data clinical patients acute lymphoblastic leukemia focus particular problem identifying genes whose expression patterns associated duration remission question great practical interest since relapse major concern treatment disease explore effects ignoring uncertainty expression estimates selection ranking genes across multiply imputed data sets variable selection methods stepwise regression criterion based strategies include exclude particular variables typically result models different selected predictors thus presenting problem combining separate complete data analyses drawing bayesian framework propose two alternative strategies address problem choosing among linear regression models missing covariates one approach call impute select involves initially performing multiple imputation applying bayesian variable selection multiply imputed data sets second strategy conduct bayesian variable selection missing data imputation simultaneously within one gibbs sampling process call simultaneously impute select sias methods implemented evaluated bayesian procedure known stochastic search variable selection multivariate normal data sets strategies offer general frameworks within different bayesian variable selection algorithms could used types data sets mental health services utilization among children foster care programs used illustrate techniques simulation sias outperform complete case analysis stepwise variable selection sias slightly outperforms variable selection essential part statistical analysis yet somewhat neglected context longitudinal data analysis propose generalized version mallows c p gc p suitable parametric nonparametric models gc p estimate measure model adequacy prediction examine performance popular marginal longitudinal models fitted gee contrast typically done practice variable selection based wald type score type tests application real data merits approach time emphasizing robust features inherent gc p investigates performance frequentist sense bayesian confidence intervals cis difference proportions relative risk odds ratio x contingency tables consider beta priors logit normal priors related correlated priors two binomial parameters goal analyze whether certain settings prior parameters tend good coverage performance regardless true association parameter values relative risk odds ratio recommend tail intervals highest posterior density hpd intervals invariance reasons protect potentially poor coverage probabilities effect large best diffuse prior recommend jeffreys prior otherwise relatively small samples bayesian cis informative even uniform priors tend poorer performance frequentist cis based inverting score tests perform uniformly quite well parameters comparing follow measurements two independent populations missing records may arise due censoring events whose occurrence associated baseline covariates situations inferences based completely followed observations may biased follow measurements covariates correlated describes exact inference class modified u covariate dependent dropouts method involves weighing permutation according retention probabilities thus requires estimation missing data mechanism proposed procedure nonparametric distributional assumption necessary outcome variables missingness patterns monte carlo approximation gibbs sampler proposed fast accurate via simulation method illustrated two small data sets asymptotic inferential procedures may appropriate o brien biometrics introduced simple nonparametric test procedure testing whether multiple outcomes one treatment group consistently larger values outcomes treatment group first explore theoretical properties o brien test extend general nonparametric behrens fisher problem assumption made regarding shape distributions conditions o brien test controls error probability asymptotically fails adjusted tests conditions hold throughout assume outcomes continuous simulations performed compare adjusted tests o brien test difference illustrated data parkinson disease clinical trial goal phase ii trial oncology evaluate efficacy new therapy dose investigated phase ii trial usually estimate maximum tolerated dose obtained preceding phase trial estimate imprecise stopping rules toxicity used many phase ii trials give recommendations construct stopping rules monitor toxicity continuously table provided pocock stopping boundaries easily obtained range toxicity rates sample sizes estimation probability toxicity response discussed group sequential designs often used periodically assessing treatment efficacy course clinical trial following group sequential test p values computed assumption data gathered according fixed sample design longer uniformly distributed null treatment effect various sample space orderings proposed computing proper p values following group sequential test although many proposed orderings compared setting time invariant treatment effects little attention given performance effect treatment within individual varies time interest compare two commonly used methods computing proper p values following group sequential test based upon analysis time z statistic orderings respect resulting power functions treatment effects survival delayed power ordering heavily influenced presence delayed treatment effect power functions corresponding z statistic ordering remain robust time varying treatment effects due natural artificial clustering multivariate survival data often arise biomedical example dental involving multiple teeth certain proportion population expected experience event interest considered cured insusceptible model correlated clustered failure time data incorporating surviving fraction propose two forms cure rate frailty models one model naturally introduces frailty based biological considerations motivated cox proportional hazards frailty model formulate likelihood functions based piecewise constant hazards derive full conditional distributions gibbs sampling bayesian paradigm opposed cox frailty model proposed methods great potential modeling multivariate survival data cure fraction illustrate cure rate frailty models root canal therapy data set failure time analysis sometimes observe additional enter period late entries treated left truncated data statistical real data substantial possibility delayed entries may extremely different hazards compared standard focus situation entry bias might arise analysis survival data purpose present develop appropriate methodology making inference data including late entries construct model includes parameters effect delayed entry bias specification distribution entry time discuss likelihood inference based model derive asymptotic behavior estimates simulation conducted finite sample size order compare analysis method standard method independence entry time failure time assumed apply method mortality analysis among atomic bomb survivors defined geographical region chronic life threatening diseases often involve mortality morbidity observational data may administrative left truncation right censoring mortality morbidity may correlated mortality may censor morbidity lynden bell estimator left truncated right censored data may biased estimating marginal survival function nonterminal event propose semiparametric estimator survival function based joint model two time event variables utilizes gamma frailty specification region observable data first develop novel estimator gamma frailty parameter left truncation estimator derive closed form estimator marginal distribution nonterminal event large sample properties estimators established via asymptotic theory methodology performs well moderate sample sizes simulations analysis data diabetes registry recent interest reproductive health research investigate validity marker event onset menopausal transition estimate age menopause age marker event propose varying coefficient cox model investigate association age marker event defined specific bleeding pattern change age menopause events censoring association varies age marker event estimation proceeds regression spline method proposed method applied tremin trust data evaluate association age onset day menstrual cycle age menopause performance proposed method evaluated simulation supplemented case control design consists case control sample additional sample disease free arise given stratum one measured exposures case control supplemental data might example arise population survey conducted independently case control design improves precision estimates main effects especially joint exposures particularly joint exposures uncommon prevalence one exposures first present pseudo likelihood estimator ple easy compute adapt two phase design methods maximum likelihood estimates mles log odds ratios design derive asymptotic variance estimators appropriately account differences sampling schemes design traditional two phase design illustration design present conducted assess influence joint exposure hepatitis b virus hbv hepatitis c virus hcv infection risk hepatocellular carcinoma data qidong county jiangsu province china characterizing process molecular cellular level changes occur time broad implications clinical decision making help knowledge disease etiology across many complex diseases presents analytic challenge due large number potentially relevant biomarkers complex uncharacterized relationships among propose exploratory bayesian model selection procedure searches model simplicity independence testing multiple discrete biomarkers measured time bayes factor calculations used identify compare models best supported data large model spaces e large number multi leveled biomarkers propose markov chain monte carlo mcmc stochastic search algorithm finding promising models apply procedure explore extent htv genetic changes occur independently time evaluation diagnostic accuracy tests gold standard disease status required many complex diseases impossible unethical obtain gold standard imperfect standard used estimated accuracy tests would biased type bias called imperfect gold standard bias develop nonparametric maximum likelihood method estimating roc curves areas ordinal scale tests absence gold standard simulation proposed estimators roc curve areas good finite sample properties terms bias mean squared error simulation nonparametric approach comparable binormal parametric method easier implement illustrate application proposed method real clinical assessing accuracy seven specific pathologists detecting carcinoma situ uterine cervix consider problem estimating bacterial concentration substance given microbial count data bayesian approach proposed naturally allows incorporation plate count data extra information confirmatory tests genotyping polymerase chain reaction pcr estimation methods yield posterior credible regions bacterial concentration contrast previous methods generally produce point estimates approach illustrated specific reference enumeration food borne pathogen escherichia coli o spiral plating although methodology applied bacterium counting method interest obtained guidance experimenter number confirmatory tests performed suggest initial plate count one err side including rather excluding colonies whose genotype seems unclear statisticians analyzing spatial data often need detect model associations based upon distances earth surface accurate computation distances sought exploratory interpretation purposes well developing numerically stable estimation algorithms data come locations spherical earth application euclidean planar metrics computing distances straightforward yet planar metrics desirable easier interpretability easy availability software packages well established theoretical properties distance computations indispensable spatial modeling importance impact upon statistical estimation prediction gone largely unaddressed explores different options planar metrics investigates impact upon spatial modeling ridout hinde demetrio biometrics derived score test testing zero inflated poisson zip regression model zero inflated negative binomial zinb alternatives mentioned score test normal approximation might underestimate nominal significance level possibly small sample cases remedy problem parametric bootstrap method proposed bootstrap method keeps significance level close nominal one greater power uniformly existing normal approximation testing note response wouters et al biometrics compared three methods exploring gene expression data contrary summary principal component analysis informative possible determine principal component analyses useful exploratory analysis microarray data present another biplot representation ge biplot gene expression biplot useful method exploring gene expression data major advantage able aid interpretation samples genes relative discusses boys henderson biometrics authors propose new approach classification genomic dna number hidden markov states variable order dependency potentially allowing throughput detection structure within genomic dna likely point departure modeling type question whether genome bacteriophage lambda appropriate example method effectiveness whether expected method carry genomes one direction transcription operon structure suggest graphical display seems offer insight would interesting see analysis uses codon alphabet recent scientific evolutions force us rethink profession position scientific map relation neighboring professions ones traditionally strong collaborative links well newly emerging fields within diverse professional group great inspiration drawn history fact early days society recent inspiring example set late rob kempton died suddenly months become president international biometric society propose method clustering produces tight stable clusters without forcing points clusters methodology general initially motivated cluster analysis microarray experiments current algorithms aim assign genes clusters many biological mainly interested identifying informative tight stable clusters sizes say genes investigation w want avoid contamination tightly regulated expression patterns biologically relevant genes due genes whose expressions loosely compatible patterns tight clustering developed specifically address problem applies k means clustering intermediate clustering engine early truncation hierarchical clustering tree used overcome local minimum problem k means clustering tightest stable clusters identified sequential manner analysis tendency genes grouped together repeated resampling validated method simulated example applied analyze set expression profiles embryonic stem cells linear model right censored responses many potential explanatory variables regression parameter estimates may unstable covariates outnumber uncensored observations estimable propose iterative algorithm partial least squares based buckley james estimating equation estimate covariate effect predict response future given set covariates leave two cross validation method empirically selecting number components partial least squares fit approximately minimizes error estimating covariate effect future observation simulation compare methods discussed dimension reduction techniques data aids clinical trials group protocol used motivate methodology false discovery rate fdr procedure become popular method handling multiplicity dimensional data definition fdr natural bayesian interpretation expected proportion null hypotheses mistakenly rejected given measure evidence truth propose controlling positive fdr bayesian approach rejection rule based posterior probabilities null hypotheses correspondence bayesian frequentist measures evidence testing studied several contexts extend comparison multiple testing control fdr illustrate procedure application wavelet thresholding problem consists recovering signal noisy measurements involves extracting wavelet coefficients result true signal formulated multiple hypotheses testing problem simulated examples compare performance approach benjamini hochberg journal royal statistical society series b procedure illustrate method nuclear magnetic resonance spectral data human brain constructing maps dry deposition pollution levels vital air quality management presents statistical problems typical many environmental spatial applications ideally maps would based dense network monitoring stations exist instead two main sources information dry deposition levels united states one pollution measurements sparse set monitoring stations called castnet output regional scale air quality models called models related problem evaluation numerical models air quality applications crucial control strategy selection develop formal methods combining sources information different spatial resolutions evaluation numerical models specify simple model models output castnet observations terms unobserved ground truth estimate model bayesian way improved spatial prediction via posterior distribution ground truth allows us validate models via posterior predictive distribution castnet observations enables us remove bias models output apply methods data concentrations obtain resolution distributions combining observed data model output conclude numerical models perform worse areas closer power plants values overestimated models present hierarchical extension cormack jolly seber cjs model open population capture recapture data addition recaptures marked animals model first captures animals losses capture parameter set includes capture probabilities survival rates birth rates survival rates birth rates treated random sample bivariate distribution thus model explicitly incorporates correlation demographic rates key feature model likelihood function includes cjs model factor expressed entirely terms identifiable parameters losses capture factored model since computational complexity classical likelihood methods prohibitive markov chain monte carlo bayesian analysis describe efficient candidate generation scheme metropolis hastings sampling cjs models extensions procedure illustrated mark recapture data moth gonodontis bidentata investigate role genetics development cancer developed new approach analyze data prostate breast colorectal cancer swedish danish finnish twin registries monozygotic mz sex dizygotic dz twins spirit sensitivity analysis modeled genetic inheritance either autosomal recessive dominant cancer susceptibility cs genotype involves either single gene many genes equal allele frequencies three genes ninefold range allele frequencies modeled joint probability cancer incidence among five age categories conditional presence absence cs genotype main assumptions joint distribution unobserved environmental effects twin pair conditional presence absence cs genotype mz dz twins probability cancer conditional presence absence cs genotype unobserved environmental effects e gene environment interaction mz dz twins probability cancer independent twins cs genotype estimation maximum likelihood via search allele frequency two levels em algorithms models acceptable good fits variability estimated bootstrap approach replications feasible th percentile bootstrap replications estimated fraction cancers cs genotype ranged various genetic models prostate cancer breast cancer colorectal cancer conclude genetic susceptibility makes small moderate contribution incidence prostate breast colorectal cancer often jointly modeling longitudinal survival data interested multivariate longitudinal measure may fit well linear models overcome problem propose joint longitudinal survival model nonparametric model longitudinal markers cubic b splines specify longitudinal model proportional hazards model link longitudinal measures hazard fit model markov chain monte carlo algorithm nw select number knots cubic b spline model conditional predictive ordinate cpo deviance information criterion dic method model selection approach validated simulation apply method examine link viral load cd count time event data aids clinical trial cubic b spline model good fit longitudinal data could obtained simple parametric models problems missing latent data standard approach first impute unobserved data perform statistical analyses completed dataset corresponding observed data imputed unobserved data standard procedures complete data inference extend approach model checking demonstrating advantages completed data model diagnostics imputed completed datasets approach set theoretical framework bayesian posterior predictive checks missing data imputation methods missing data model checking interpreted predictive inference non bayesian context consider graphical diagnostics within framework advantages completed data approach include one often check model fit terms quantities key substantive interest natural way always possible observed data alone problems missing data checks may devised net require model missingness inclusion mechanism latter useful analysis ignorable unknown data collection mechanisms often assumed analysis sample surveys observational many problems latent data possible check qualitative features model example independence two variables naturally formalized help latent data illustrate several applied examples advantage supremum log rank standard log rank statistic increased sensitivity wider variety stochastic ordering alternatives develop formula sample size computation utilizing supremum log rank statistic idea base power proportional hazards alternative supremum log rank power standard log rank setting standard log rank optimal slight increase sample size required standard log rank example increase occurs two sided test type error power slight increase sample size offset significant gains power supremum log rank test achieves wide range nonproportional hazards alternatives small simulation used illustration facilitate wider supremum log rank statistic clinical trials predictive accuracy survival model summarized extensions proportion variation explained model r commonly used continuous response models extensions sensitivity specificity commonly used binary response models propose new time dependent accuracy summaries based time specific versions sensitivity specificity calculated risk sets connect accuracy summaries previously proposed global concordance measure variant kendall tau addition standard cox regression output used obtain estimates time dependent sensitivity specificity time dependent receiver operating characteristic roc curves semiparametric estimation methods appropriate proportional nonproportional hazards data introduced evaluated simulations illustrated two familiar survival data sets consider two groups individuals infected population genetically related heterogeneous mixture viruses multiple viral sequences sampled person based estimates genetic distances pairs aligned viral sequences within individuals develop four new tests compare intra individual genetic sequence diversity two groups problem complicated two levels dependency data structure within individual pairwise distances share common sequence positively correlated ii two pairings individuals share person two differences intra individual distances paired individuals positively correlated first proposed test based difference mean intra individual pairwise distances pooled individuals group standardized variance estimate corrects correlation structure u statistic theory second procedure nonparametric rank based analog first test third test contrasts set specific average intra individual pairwise distances groups tests easy solve correlation problem fourth procedure based linear combination possible u calculated independent identically distributed sequence subdatasets two levels ii dependencies data complicated tests powerful although proposed methods empirical fully utilize knowledge population genetics tests reflect biology evolutionary models used derive pairwise sequence distances new tests evaluated theoretically simulation applied dataset hiv sequences sampled children adaptive designs used phase iii clinical trials skewing allocation pattern toward better treatments optimum design theory derive skewed bayesian biased coin procedure sequential designs continuous responses skewed designs used adaptive designs performance studied numerically theoretically properties loss proportion allocation better treatment reproductive scientists couples attempting pregnancy interested identifying predictors day specific probabilities conception relation timing single intercourse act menstrual cycles multiple days intercourse occurrence conception represents aggregation across bernoulli trials intercourse day data structure dependency among multiple cycles woman implementing analyses challenging proposes bayesian approach based generalization barrett marshall model incorporate woman specific frailty day specific covariates model simple closed form expression marginal probability conception auxiliary variables formulation facilitates efficient posterior computation although motivated fecundability approach used efficient variable selection model averaging general applications categorical discrete event time data multi list methods become common application capture recapture methodology estimate size human populations successfully applied estimating prevalence diabetes human immunodeficiency virus hiv drug abuse key assumption multi list methods individuals unique tag allows matched across lists develops multi list methodology relaxes assumption single tag common lists estimates found estimating functions example illustrates application estimating prevalence diabetes simulation investigates conditions methodology robust different list population sizes estrous cycling data contain sequences characters e g dpemd sequence represents animal estrous cycle character indicating daily estrous cycle stage changes estrous cycle pattern determined estrous stage lengths information adverse events stage lengths directly observable interval censored lengths first last stages sequence extracted data propose markov chain model approximate estrous cycling process transition probabilities one stage another derived conditioning stage lengths assuming weibull distribution stage lengths second weibull parameter depending upon treatment effects animal specific random effects regression models censored stage lengths fitted bayesian approach used inference dose effects analysis implemented mcmc method winbugs estrous cycling data set national toxicology program analyzed example alternative mean regression model quantile regression model studied extensively independent failure time data due natural artificial clustering common encounter multivariate failure time data biomedical research intracluster correlation needs accounted appropriately right censored correlated survival data investigate quantile regression model adapt estimating equation approach parameter estimation working independence assumption well weighted version enhancing efficiency parameter estimates consistent asymptotically follow normal distributions variance estimation asymptotic approximation involves nonparametric functional density estimation employ bootstrap perturbation resampling methods estimation variance covariance matrix examine proposed method finite sample sizes simulation illustrate data clinical trial otitis media many settings interlaboratory testing small area estimation sample surveys heritability investigators interested estimating covariance components multivariate measurements presence outliers seriously distort estimates obtained standard procedures maximum likelihood propose procedure based m estimation robustly estimating multivariate covariance components presence outliers procedure applies balanced unbalanced data present algorithm computing robust estimates examine performance estimator simulation estimator used covariance components identify outliers variability egg length breadth measurements american coots mean residual life function average remaining life surviving varies time proportional mean residual life model proposed oakes dasu biometrika regression analysis association related covariates absence censoring develop semiparametric estimation procedures take censoring account proposed methodology evaluated via simulation applied clinical trial chemotherapy postoperative radiotherapy lung cancer patients derive first order bias corrected maximum likelihood estimator negative binomial dispersion parameter estimator compared terms bias efficiency maximum likelihood estimator investigated piegorsch biometrics moment maximum extended quasi likelihood estimators investigated clark perry biometrics double extended quasi likelihood estimator bias corrected maximum likelihood estimator superior bias efficiency properties instances ease comparison give two parameter negative binomial model example involving negative binomial regression given case control commonly used whether candidate allele disease associated spurious association arise due population substructure cryptic relatedness cause variance trend test increase devlin roeder derived appropriate variance inflation factor vif trend test proposed novel genomic control gc approach estimate vif adjust test statistic derived assuming additive genetic model corresponding vif independent candidate allele frequency determine appropriate vifs recessive dominant models unlike additive test vifs optimal tests two models depend candidate allele frequency simulation null loci used estimate vif allele frequencies similar candidate gene gc tests derived recessive dominant models remain optimal underlying genetic model unknown null loci candidate gene quite different allele frequencies gc tests derived recessive dominant models cannot used gc test derived additive model many chronic conditions alternate active inactive state sojourns active state may involve multiple lesions infections recurrences different times onset resolution present biologically interpretable model chronic recurrent conditions based queueing process model birth death process describing recurrences semi markov process describing alternation active inactive states fit panel data binary assessment active inactive state series discrete time points hidden markov approach accommodate individual heterogeneity covariates random effects model simulate posterior distribution unknowns markov chain monte carlo algorithm application clinical trial genital herpes method characterize biology disease estimate treatment efficacy presents stochastic model designed analyze experimental data development cell clones composed two distinct types cells proposed model extension traditional multi type bellman harris branching stochastic process allowing nonidentical time transformation distributions defined different cell types simulated pseudo likelihood method developed parametric statistical inference experimental data cell clones proposed model method uses simulation based approximations means variance covariance matrices cell counts proposed estimator vector unknown parameters strongly consistent asymptotically normal mild regularity conditions variance covariance matrix estimated parametric bootstrap monte carlo wald test proposed test hypotheses finite sample properties estimator studied computer simulations model associated methods parametric inference applied analysis proliferation differentiation cultured o progenitor cells play key role development central nervous system follows analysis time division progenitor cell time differentiation oligodendrocyte identically distributed biological finding suggests molecular event determining type cell transformation likely occur start rather end mitotic cycle multivariate failure time data propose new class shared gamma frailty models imposing box cox transformation hazard function product baseline hazard frailty novel class models allows broad range shapes relationships hazard baseline hazard functions includes well known cox gamma frailty model new additive gamma frailty model two special cases due nonnegative hazard constraint shared gamma frailty model computationally challenging bayesian paradigm joint priors constructed conditional marginal specification conditional distribution univariate absorbs nonlinear parameter constraints marginal part prior specification free constraints prior distributions allow us easily compute full conditionals needed gibbs sampling incorporating constraints class shared gamma frailty models illustrated real dataset objective phase trial two agents set maximum tolerated dose combinations yield prespecified toxicity rate consider case several doses one agent fixed goal maximum tolerated dose agent used combination doses agent one propose bayesian design uses parsimonious working model dose toxicity relationship new design effective identifying maximum tolerated combinations one dimensional designs applied dose level one agents typically regression models competing risks outcomes based proportional hazards models crude hazard rates estimates often agree impressions drawn plots cumulative incidence functions level risk factor present technique models cumulative incidence functions directly method based pseudovalues jackknife statistic constructed cumulative incidence curve pseudovalues used generalized estimating equation obtain estimates model parameters properties estimator apply technique effect alternative donors relapse patients given bone marrow transplant leukemia propose discrete time bayesian hierarchical model population dynamics great gerbil flea ecological system model accounts sampling variability arising data originally collected purposes prior unknown population densities incorporates specific biological hypotheses regarding interacting dynamics two species well life cycles density dependent effects included posterior estimates obtained via markov chain monte carlo variance observed density estimates quadratic function unknown density indicates presence density dependent growth rate gerbil population flea population clear evidence density dependent summer net growth dependent flea gerbil ratio beginning reproductive summer winter net growth favored density estimate average gerbil population survives winter hierarchical bayesian models useful extracting ecobiological information observational data presents aid monitoring clinical trials failure time endpoints based bayesian nonparametric analyses data posterior distribution mixture dirichlet processes presence censoring one assumes dirichlet process prior survival distribution gibbs sampling one generate random samples posterior distribution samples posterior distributions treatment specific survival curves one evaluate current evidence favor stopping continuing trial based summary survival curves method nonparametric easily used example situations hazards cross suspected cross relevant clinical decisions might based estimating integral curves might expected become positive favor new toxic therapy example based actual trial illustrates method effort determine whether particular treatment causes particular outcome event data obtained database system records events occur events system records exposure treatment system records information cases system information events might occurred units cases roughly speaking know number successes two proportions treated control numbers trials units proportions indeed concept trial may vague information situation quite hopeless interesting strategy sometimes used entails identifying two types cases whose origin entirely different known cases second type definitely affected treatment strategy case case case seems reinvented independently many times recently offered general strategy infectious disease epidemiology mccarthy giesecke international journal epidemiology strategy permit estimation number cases caused treatment attributable effects new way method exact inference proposed along large sample approximation two examples discussed one concerning effects daytime running lights drls risk multivehicle accidents concerning origin salmonella infection counterexample superficially similar appearance discussed concerning suicide rates following publication final exit treatment may outcome may alter type attributable effect cannot estimated many practical problems testing involves nuisance parameter appears alternative davies biometrika proposed maximum score whole range nuisance parameter test statistic type testing freidlin podgor gastwirth biometrics studied two simpler maximum test maximum score two extreme points nuisance parameter maximum score three points nuisance parameter including two extreme points compare powers three maximum type context three genetic problems performance medical diagnostic test often evaluated comparing outcome test patient true disease state receiver operating characteristic analysis may used summarize test accuracy analysis may encounter several complications actual practice one complication verification bias e gold standard assessment disease status may partially available probability ascertainment disease may depend test result characteristics second issue tests interpreted rater may independent estimating equations generalize previous methods address problems contrast performance alternative estimators accuracy robust sandwich variance estimators permit valid asymptotic inference suggest context observational cohort rich covariate information available weighted estimating equations approach may preferable robustness model misspecification apply methodology mammography performed community radiologists two goals multiple dose factorial trials demonstrating improved effectiveness fixed combination components well ii identifying safe effective dose range authors address goals though focus second closure procedures guarantee strong control familywise error rate two different families null hypotheses investigated bi factorial dose response designs monotone respect matrix partial order one suitable minimum effective dose one large enough identify highest effective dose step likelihood ratio tests appropriate multiple contrast tests applied unbalanced clinical trial example taken hung medicine full computer code written r language available internet primary objective quantitative risk safety assessment characterization severity likelihood adverse effect caused chemical toxin pharmaceutical agent many cases data available doses exposures agent inferences doses must based dose data modern method making dose inferences known benchmark analysis attention centers dose fixed benchmark level risk achieved upper confidence limits risk confidence limits benchmark dose interest practice number possible benchmark risks may corrections must applied adjust limits multiplicity short note discuss approaches quantal response data mcnemar test popular assessing difference proportions two observations taken experimental unit useful variety epidemiological designs produce correlated binary outcomes involving outcome ascertainment cost feasibility concerns often lead researchers employ error prone surrogate diagnostic tests assuming available gold standard diagnostic method address point confidence interval estimation true difference proportions paired data odds ratio incorporating external internal validation data distinguish two special cases depending whether reasonable assume diagnostic test properties remain assessments e g baseline follow likelihood based analysis yields closed form estimates validation data external requires numeric optimization internal latter approach offers advantages terms robustness efficient odds ratio estimation consider internal validation designs geared toward optimizing efficiency given fixed cost allocated measurements two motivating examples presented gold standard surrogate bivariate binary diagnoses bacterial vaginosis bv women participating hiv epidemiology research work aims applying concepts generalizability theory data resulting clinical trials focus sources variance impact reliability generalizability psychiatric measurement scale goal identify measure thereby potentially strategies reduce influence sources measurement question future trials approach originally devised cronbach associates known generalizability theory work full modeling power mixed models used generalizability data five double blind randomized clinical trials comparing effects risperidone conventional antipsychotic agents treatment chronic schizophrenia clinical trials advanced stage disease often interest perform treatment comparisons endpoints defined survivors examples include time ventilation ventilation change quality life health related quality life duration response therapy therapeutic trials randomized treatment comparisons endpoints cannot performed outcomes defined nonrandomly selected subgroup survivors propose new evaluation survivor average causal effect sace treatment comparisons nature estimator sace presence unmeasured confounders nontestable assumption identifies sace outline sensitivity analysis exploring robustness conclusions deviations assumption apply method duration ventilation clinical trial acute respiratory distress syndrome
